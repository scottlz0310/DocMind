"""
EmbeddingManagerå¼·åŒ–ãƒ†ã‚¹ãƒˆ

åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
Phase7å¼·åŒ–ç‰ˆã®å†…å®¹ã‚’çµ±åˆæ¸ˆã¿ã€‚
"""

import os
from pathlib import Path
import shutil
import tempfile

import numpy as np
import pytest

from src.core.embedding_manager import EmbeddingManager


class TestEmbeddingManager:
    """åŸ‹ã‚è¾¼ã¿ç®¡ç†ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def temp_cache_dir(self):
        """ãƒ†ã‚¹ãƒˆç”¨ä¸€æ™‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"""
        temp_dir = tempfile.mkdtemp()
        yield Path(temp_dir)
        shutil.rmtree(temp_dir)

    @pytest.fixture
    def sample_texts(self):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«"""
        return [
            "æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®é‡è¦ãªåˆ†é‡ã§ã™",
            "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã§ã¯çµ±è¨ˆçš„æ‰‹æ³•ã‚’ä½¿ç”¨ã—ã¾ã™",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯è«–ç†çš„æ€è€ƒãŒå¿…è¦ã§ã™",
            "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã«ã¯ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒé‡è¦ã§ã™",
            "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã¯è¨ˆç”»ã¨å®Ÿè¡ŒãŒéµã¨ãªã‚Šã¾ã™",
        ]

    def test_embedding_generation_accuracy(self, temp_cache_dir, sample_texts):
        """åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆç²¾åº¦ãƒ†ã‚¹ãƒˆ"""
        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        for text in sample_texts:
            embedding = manager.generate_embedding(text)

            # åŸºæœ¬æ¤œè¨¼
            assert isinstance(embedding, np.ndarray)
            assert embedding.shape[0] > 0  # ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒæ•°
            assert not np.isnan(embedding).any()  # NaNå€¤ãªã—
            assert not np.isinf(embedding).any()  # ç„¡é™å€¤ãªã—

            # æ­£è¦åŒ–ç¢ºèª(sentence-transformersã¯æ­£è¦åŒ–æ¸ˆã¿)
            norm = np.linalg.norm(embedding)
            assert abs(norm - 1.0) < 0.1  # æ­£è¦åŒ–æ¸ˆã¿ãƒ™ã‚¯ãƒˆãƒ«(è¨±å®¹ç¯„å›²ã‚’åºƒã’ã‚‹)

    def test_embedding_cache_performance(self, temp_cache_dir, sample_texts):
        """åŸ‹ã‚è¾¼ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        import time

        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # åˆå›ç”Ÿæˆæ™‚é–“æ¸¬å®š(ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŸ‹ã‚è¾¼ã¿ã¨ã—ã¦è¿½åŠ )
        start_time = time.time()
        manager.add_document_embedding("doc1", sample_texts[0])
        first_time = time.time() - start_time

        # åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã§å†åº¦è¿½åŠ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ)
        start_time = time.time()
        manager.add_document_embedding("doc1", sample_texts[0])
        cache_time = time.time() - start_time

        # æ¤œè¨¼
        assert cache_time < first_time  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ–¹ãŒé«˜é€Ÿ
        assert cache_time < 0.1  # 100msä»¥å†…

    def test_batch_embedding_efficiency(self, temp_cache_dir, sample_texts):
        """ãƒãƒƒãƒåŸ‹ã‚è¾¼ã¿åŠ¹ç‡ãƒ†ã‚¹ãƒˆ"""

        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # å€‹åˆ¥å‡¦ç†
        individual_embeddings = []
        for i, text in enumerate(sample_texts):
            manager.add_document_embedding(f"doc{i}", text)
            individual_embeddings.append(manager.embeddings[f"doc{i}"].embedding)

        # æ–°ã—ã„ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§åŒã˜å‡¦ç†(ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—)
        manager2 = EmbeddingManager(embeddings_path=str(temp_cache_dir / "embeddings2.pkl"))
        for i, text in enumerate(sample_texts):
            manager2.add_document_embedding(f"doc{i}", text)

        # æ¤œè¨¼(å‡¦ç†æ™‚é–“ã®æ¯”è¼ƒ)
        assert len(manager.embeddings) == len(sample_texts)
        assert len(manager2.embeddings) == len(sample_texts)

    def test_similarity_calculation_accuracy(self, temp_cache_dir):
        """é¡ä¼¼åº¦è¨ˆç®—ç²¾åº¦ãƒ†ã‚¹ãƒˆ"""
        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # é¡ä¼¼ãƒ†ã‚­ã‚¹ãƒˆ
        text1 = "æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®åˆ†é‡ã§ã™"
        text2 = "äººå·¥çŸ¥èƒ½ã«ãŠã‘ã‚‹æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦"

        # éé¡ä¼¼ãƒ†ã‚­ã‚¹ãƒˆ
        text3 = "ä»Šæ—¥ã®å¤©æ°—ã¯æ™´ã‚Œã§ã™"

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŸ‹ã‚è¾¼ã¿ã‚’è¿½åŠ 
        manager.add_document_embedding("doc1", text1)
        manager.add_document_embedding("doc2", text2)
        manager.add_document_embedding("doc3", text3)

        # é¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿè¡Œ
        results = manager.search_similar(text1, limit=10)

        # æ¤œè¨¼
        assert len(results) > 0
        # æœ€åˆã®çµæœã¯è‡ªåˆ†è‡ªèº«(doc1)ã§é¡ä¼¼åº¦ãŒæœ€ã‚‚é«˜ã„
        assert results[0][0] == "doc1"
        assert results[0][1] > 0.9  # è‡ªåˆ†è‡ªèº«ã¨ã®é¡ä¼¼åº¦ã¯é«˜ã„

    def test_embedding_persistence(self, temp_cache_dir, sample_texts):
        """åŸ‹ã‚è¾¼ã¿æ°¸ç¶šåŒ–ãƒ†ã‚¹ãƒˆ"""
        embeddings_path = str(temp_cache_dir / "embeddings.pkl")

        # æœ€åˆã®ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        manager1 = EmbeddingManager(embeddings_path=embeddings_path)
        for i, text in enumerate(sample_texts):
            manager1.add_document_embedding(f"doc{i}", text)

        # ä¿å­˜
        manager1.save_embeddings()

        # æ–°ã—ã„ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿
        manager2 = EmbeddingManager(embeddings_path=embeddings_path)

        # æ¤œè¨¼
        assert len(manager2.embeddings) == len(sample_texts)
        for i in range(len(sample_texts)):
            assert f"doc{i}" in manager2.embeddings

    def test_large_text_handling(self, temp_cache_dir):
        """å¤§ããªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆ(ãƒ¢ãƒ‡ãƒ«ã®æœ€å¤§é•·ã‚’è¶…ãˆã‚‹å¯èƒ½æ€§)
        long_text = "ã“ã‚Œã¯éå¸¸ã«é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚" * 1000

        embedding = manager.generate_embedding(long_text)

        # æ¤œè¨¼
        assert isinstance(embedding, np.ndarray)
        assert embedding.shape[0] > 0
        assert not np.isnan(embedding).any()

    def test_memory_efficient_processing(self, temp_cache_dir):
        """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„å‡¦ç†ãƒ†ã‚¹ãƒˆ"""

        import psutil

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss

        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # å¤§é‡ã®ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
        texts = [f"ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ{i}ã§ã™ã€‚" * 10 for i in range(100)]  # æ•°ã‚’æ¸›ã‚‰ã™

        for i, text in enumerate(texts):
            manager.add_document_embedding(f"doc{i}", text)

        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory

        # ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡ãŒ500MBä»¥ä¸‹(ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚’è€ƒæ…®)
        assert memory_increase < 500 * 1024 * 1024

    @pytest.mark.skipif(True, reason="ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆã¯PyTorch meta tensorå•é¡Œã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
    def test_concurrent_embedding_generation(self, temp_cache_dir):
        """ä¸¦è¡ŒåŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ(ã‚¹ã‚­ãƒƒãƒ—)"""
        # PyTorchã®meta tensorå•é¡Œã®ãŸã‚ã€ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
        # å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã®ä½¿ç”¨ã‚’æ¨å¥¨
        pass

    def test_error_handling_robustness(self, temp_cache_dir):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å …ç‰¢æ€§ãƒ†ã‚¹ãƒˆ"""
        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # ç©ºæ–‡å­—åˆ—
        embedding = manager.generate_embedding("")
        assert embedding is not None
        assert isinstance(embedding, np.ndarray)

        # ç‰¹æ®Šæ–‡å­—
        embedding = manager.generate_embedding("!@#$%^&*()")
        assert embedding is not None
        assert isinstance(embedding, np.ndarray)

        # éASCIIæ–‡å­—
        embedding = manager.generate_embedding("ã“ã‚“ã«ã¡ã¯ä¸–ç•ŒğŸŒ")
        assert embedding is not None
        assert isinstance(embedding, np.ndarray)

    def test_cache_size_management(self, temp_cache_dir):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºç®¡ç†ãƒ†ã‚¹ãƒˆ"""
        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # è¤‡æ•°ã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        for i in range(10):
            text = f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆ{i}"
            manager.add_document_embedding(f"doc{i}", text)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºç¢ºèª
        cache_info = manager.get_cache_info()
        assert cache_info["total_embeddings"] == 10

    # Phase7çµ±åˆ: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
    def test_model_loading_with_mock(self, temp_cache_dir):
        """ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        from unittest.mock import Mock, patch

        with patch("src.core.embedding_manager.SentenceTransformer") as mock_transformer:
            mock_model = Mock()
            mock_model.encode.return_value = np.array([0.1, 0.2, 0.3])
            mock_model.get_sentence_embedding_dimension.return_value = 384
            mock_transformer.return_value = mock_model

            embeddings_path = str(temp_cache_dir / "embeddings.pkl")
            manager = EmbeddingManager(embeddings_path=embeddings_path)

            # ãƒ¢ãƒ‡ãƒ«ã‚’æ˜ç¤ºçš„ã«èª­ã¿è¾¼ã¿
            manager.load_model()

            # ãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert manager.model is not None
            assert manager.model == mock_model

    # Phase7çµ±åˆ: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
    def test_error_handling_robustness_extended(self, temp_cache_dir):
        """æ‹¡å¼µã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        from src.utils.exceptions import EmbeddingError

        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # Noneå€¤ãƒ†ã‚¹ãƒˆ - Noneã¯ç©ºæ–‡å­—åˆ—ã¨ã—ã¦å‡¦ç†ã•ã‚Œã‚‹
        embedding = manager.generate_embedding(None)
        assert embedding is not None
        assert isinstance(embedding, np.ndarray)

        # éæ–‡å­—åˆ—ãƒ†ã‚¹ãƒˆ - æ•°å€¤ã¯ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿ
        with pytest.raises(EmbeddingError):
            manager.generate_embedding(123)

    # Phase7çµ±åˆ: ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ
    def test_batch_processing_efficiency(self, temp_cache_dir, sample_texts):
        """ãƒãƒƒãƒå‡¦ç†åŠ¹ç‡ãƒ†ã‚¹ãƒˆ"""
        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # ãƒãƒƒãƒå‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        for i, text in enumerate(sample_texts):
            manager.add_document_embedding(f"batch_doc_{i}", text)

        # æ¤œè¨¼
        assert len(manager.embeddings) == len(sample_texts)
        for i in range(len(sample_texts)):
            assert f"batch_doc_{i}" in manager.embeddings

    # Phase7çµ±åˆ: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
    def test_embedding_metadata(self, temp_cache_dir, sample_texts):
        """åŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ"""
        embeddings_path = str(temp_cache_dir / "embeddings.pkl")
        manager = EmbeddingManager(embeddings_path=embeddings_path)

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŸ‹ã‚è¾¼ã¿ã‚’è¿½åŠ 
        manager.add_document_embedding("meta_doc", sample_texts[0])

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        if hasattr(manager, "get_embedding_stats"):
            stats = manager.get_embedding_stats()
            assert isinstance(stats, dict)
            assert "total_embeddings" in stats or "total_documents" in stats
        else:
            # ãƒ¡ã‚½ãƒƒãƒ‰ãŒãªã„å ´åˆã¯åŸºæœ¬çš„ãªç¢ºèª
            assert "meta_doc" in manager.embeddings
