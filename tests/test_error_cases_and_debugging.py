"""
ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã¨ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

æ§˜ã€…ãªã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã¨ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ã®çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import os
import shutil
import tempfile
import threading
import time
from pathlib import Path
from unittest.mock import Mock, patch

import pytest

from src.core.document_processor import DocumentProcessor
from src.core.file_watcher import FileWatcher
from src.core.index_manager import IndexManager
from src.core.indexing_worker import IndexingWorker
from src.data.database import DatabaseManager
from src.data.models import Document, FileType
from src.utils.error_handler import ErrorHandler
from src.utils.exceptions import DocumentProcessingError
from src.utils.logging_config import setup_logging


@pytest.mark.integration
class TestErrorCasesAndDebugging:
    """ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã¨ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(autouse=True)
    def setup(self, test_config):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.config = test_config
        self.test_folder = Path(tempfile.mkdtemp())

        # ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        self._create_error_test_files()

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.document_processor = DocumentProcessor()
        self.index_manager = IndexManager(str(self.config.index_dir))
        self.index_manager.create_index()
        self.file_watcher = Mock(spec=FileWatcher)
        self.db_manager = DatabaseManager(str(self.config.database_file))
        self.db_manager.initialize()

        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼åˆæœŸåŒ–
        self.error_handler = ErrorHandler()

        # ãƒ­ã‚°è¨­å®š
        setup_logging(self.config.log_dir)

        # ã‚·ã‚°ãƒŠãƒ«å—ä¿¡ç”¨
        self.error_signals = []
        self.completion_signals = []

        yield

        if self.test_folder.exists():
            shutil.rmtree(self.test_folder)

    def _create_error_test_files(self):
        """ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        # æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«
        (self.test_folder / "normal.txt").write_text(
            "ã“ã‚Œã¯æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚", encoding="utf-8"
        )

        # ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«
        (self.test_folder / "empty.txt").write_text("", encoding="utf-8")

        # éå¸¸ã«å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆç”¨ï¼‰
        large_content = "å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆå†…å®¹ã€‚\n" * 10000
        (self.test_folder / "large.txt").write_text(large_content, encoding="utf-8")

        # ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«å
        special_chars_file = self.test_folder / "ç‰¹æ®Šæ–‡å­—ãƒ•ã‚¡ã‚¤ãƒ«å.txt"
        special_chars_file.write_text(
            "ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚", encoding="utf-8"
        )

        # èª­ã¿å–ã‚Šå°‚ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ¨©é™ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆç”¨ï¼‰
        readonly_file = self.test_folder / "readonly.txt"
        readonly_file.write_text("èª­ã¿å–ã‚Šå°‚ç”¨ãƒ•ã‚¡ã‚¤ãƒ«", encoding="utf-8")
        readonly_file.chmod(0o444)  # èª­ã¿å–ã‚Šå°‚ç”¨ã«è¨­å®š

        # ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ï¼‰
        corrupted_file = self.test_folder / "corrupted.txt"
        with open(corrupted_file, "wb") as f:
            f.write(b"\x00\x01\x02\x03\xff\xfe\xfd")

        # éå¸¸ã«é•·ã„ãƒ•ã‚¡ã‚¤ãƒ«å
        long_name = "a" * 200 + ".txt"
        try:
            (self.test_folder / long_name).write_text(
                "é•·ã„ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ†ã‚¹ãƒˆ", encoding="utf-8"
            )
        except OSError:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãŒé•·ã„ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚µãƒãƒ¼ãƒˆã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass

        # ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        deep_dir = self.test_folder
        for i in range(10):
            deep_dir = deep_dir / f"level_{i}"
            deep_dir.mkdir()
        (deep_dir / "deep_file.txt").write_text(
            "æ·±ããƒã‚¹ãƒˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«", encoding="utf-8"
        )

    def _connect_error_signals(self, worker):
        """ã‚¨ãƒ©ãƒ¼ã‚·ã‚°ãƒŠãƒ«ã‚’æ¥ç¶š"""
        worker.error_occurred.connect(
            lambda context, error: self.error_signals.append((context, error))
        )
        worker.indexing_completed.connect(
            lambda folder, stats: self.completion_signals.append((folder, stats))
        )

    def test_file_access_permission_errors(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # èª­ã¿å–ã‚Šä¸å¯èƒ½ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        restricted_dir = self.test_folder / "restricted"
        restricted_dir.mkdir()
        (restricted_dir / "restricted_file.txt").write_text(
            "åˆ¶é™ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«", encoding="utf-8"
        )

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¨©é™ã‚’åˆ¶é™
        try:
            restricted_dir.chmod(0o000)  # ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯

            worker = IndexingWorker(
                str(self.test_folder),
                self.document_processor,
                self.index_manager,
                self.file_watcher,
            )

            self._connect_error_signals(worker)
            worker.process_folder()

            # å‡¦ç†ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚ç¶™ç¶šï¼‰
            assert (
                len(self.completion_signals) == 1
            ), "æ¨©é™ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚å‡¦ç†ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“"

            folder_path, stats = self.completion_signals[0]

            # ã‚¨ãƒ©ãƒ¼ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert (
                len(stats["errors"]) > 0 or stats["files_failed"] > 0
            ), "æ¨©é™ã‚¨ãƒ©ãƒ¼ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

        finally:
            # æ¨©é™ã‚’å¾©å…ƒã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            try:
                restricted_dir.chmod(0o755)
            except:
                pass

        print("âœ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†")

    def test_corrupted_file_handling(self):
        """ç ´æãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # DocumentProcessorã‚’ãƒ¢ãƒƒã‚¯ã—ã¦ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        with patch.object(self.document_processor, "process_file") as mock_process:

            def side_effect(file_path):
                if "corrupted.txt" in file_path:
                    raise DocumentProcessingError("ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã¾ã™")
                # ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ­£å¸¸ã«å‡¦ç†
                return Document(
                    id=f"test_{Path(file_path).stem}",
                    file_path=file_path,
                    title=Path(file_path).stem,
                    content="æ­£å¸¸ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
                    file_type=FileType.TEXT,
                    size=100,
                )

            mock_process.side_effect = side_effect

            worker = IndexingWorker(
                str(self.test_folder),
                self.document_processor,
                self.index_manager,
                self.file_watcher,
            )

            self._connect_error_signals(worker)
            worker.process_folder()

        # ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert (
            len(self.completion_signals) == 1
        ), "ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚å‡¦ç†ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“"

        folder_path, stats = self.completion_signals[0]
        assert stats["files_failed"] > 0, "ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã®å¤±æ•—ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        error_messages = " ".join(stats["errors"])
        assert (
            "corrupted.txt" in error_messages or "ç ´æ" in error_messages
        ), "ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼æƒ…å ±ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

        print("âœ“ ç ´æãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ†ã‚¹ãƒˆå®Œäº†")

    def test_memory_exhaustion_handling(self):
        """ãƒ¡ãƒ¢ãƒªä¸è¶³å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # éå¸¸ã«å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹éš›ã®ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        with patch.object(self.document_processor, "process_file") as mock_process:

            def side_effect(file_path):
                if "large.txt" in file_path:
                    raise MemoryError("ãƒ¡ãƒ¢ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                return Document(
                    id=f"test_{Path(file_path).stem}",
                    file_path=file_path,
                    title=Path(file_path).stem,
                    content="æ­£å¸¸ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
                    file_type=FileType.TEXT,
                    size=100,
                )

            mock_process.side_effect = side_effect

            worker = IndexingWorker(
                str(self.test_folder),
                self.document_processor,
                self.index_manager,
                self.file_watcher,
            )

            self._connect_error_signals(worker)
            worker.process_folder()

        # ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert (
            len(self.completion_signals) == 1
        ), "ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚å‡¦ç†ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“"

        folder_path, stats = self.completion_signals[0]
        assert stats["files_failed"] > 0, "ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ã®å¤±æ•—ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

        print("âœ“ ãƒ¡ãƒ¢ãƒªä¸è¶³å‡¦ç†ãƒ†ã‚¹ãƒˆå®Œäº†")

    def test_database_connection_errors(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # IndexManagerã‚’ãƒ¢ãƒƒã‚¯ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        with patch.object(self.index_manager, "add_document") as mock_add:
            mock_add.side_effect = Exception("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼")

            worker = IndexingWorker(
                str(self.test_folder),
                self.document_processor,
                self.index_manager,
                self.file_watcher,
            )

            self._connect_error_signals(worker)
            worker.process_folder()

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert (
            len(self.error_signals) > 0
        ), "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã‚·ã‚°ãƒŠãƒ«ãŒç™ºè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“"

        # ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèª
        error_contexts = [signal[0] for signal in self.error_signals]
        assert any(
            "batch_processing" in context for context in error_contexts
        ), "ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

        print("âœ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†")

    def test_file_watcher_initialization_errors(self):
        """FileWatcheråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # FileWatcherã‚’ãƒ¢ãƒƒã‚¯ã—ã¦ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        self.file_watcher.add_watch_path.side_effect = Exception(
            "ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼"
        )

        worker = IndexingWorker(
            str(self.test_folder),
            self.document_processor,
            self.index_manager,
            self.file_watcher,
        )

        self._connect_error_signals(worker)
        worker.process_folder()

        # FileWatcherã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert (
            len(self.error_signals) > 0
        ), "FileWatcherã‚¨ãƒ©ãƒ¼ã‚·ã‚°ãƒŠãƒ«ãŒç™ºè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“"

        error_contexts = [signal[0] for signal in self.error_signals]
        assert any(
            "file_watching" in context for context in error_contexts
        ), "ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚¨ãƒ©ãƒ¼ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

        print("âœ“ FileWatcheråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†")

    def test_unicode_and_encoding_errors(self):
        """Unicodeãƒ»ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # ç•°ãªã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        encoding_test_dir = self.test_folder / "encoding_test"
        encoding_test_dir.mkdir()

        # UTF-8ãƒ•ã‚¡ã‚¤ãƒ«
        (encoding_test_dir / "utf8.txt").write_text(
            "UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« ğŸš€", encoding="utf-8"
        )

        # Shift-JISãƒ•ã‚¡ã‚¤ãƒ«
        try:
            (encoding_test_dir / "sjis.txt").write_text(
                "Shift-JISã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«", encoding="shift-jis"
            )
        except UnicodeEncodeError:
            # Shift-JISã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass

        # ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦èª­ã¿å–ã‚ã†ã¨ã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ï¼‰
        with open(encoding_test_dir / "binary.txt", "wb") as f:
            f.write(b"\xff\xfe\x00\x01\x02\x03")

        worker = IndexingWorker(
            str(encoding_test_dir),
            self.document_processor,
            self.index_manager,
            self.file_watcher,
        )

        self._connect_error_signals(worker)
        worker.process_folder()

        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚å‡¦ç†ãŒå®Œäº†ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert (
            len(self.completion_signals) == 1
        ), "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚å‡¦ç†ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“"

        print("âœ“ Unicodeãƒ»ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†")

    def test_concurrent_access_conflicts(self):
        """ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ç«¶åˆãƒ†ã‚¹ãƒˆ"""
        # åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«å¯¾ã—ã¦è¤‡æ•°ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åŒæ™‚å®Ÿè¡Œ
        workers = []
        threads = []
        all_error_signals = []
        all_completion_signals = []

        for _i in range(3):
            worker = IndexingWorker(
                str(self.test_folder),
                self.document_processor,
                self.index_manager,
                self.file_watcher,
            )

            # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ã®ã‚·ã‚°ãƒŠãƒ«åé›†
            worker_errors = []
            worker_completions = []

            worker.error_occurred.connect(
                lambda context, error, we=worker_errors: we.append((context, error))
            )
            worker.indexing_completed.connect(
                lambda folder, stats, wc=worker_completions: wc.append((folder, stats))
            )

            workers.append(worker)
            all_error_signals.append(worker_errors)
            all_completion_signals.append(worker_completions)

        # ä¸¦è¡Œå®Ÿè¡Œ
        def run_worker(worker):
            worker.process_folder()

        for worker in workers:
            thread = threading.Thread(target=run_worker, args=(worker,))
            threads.append(thread)
            thread.start()

        # å…¨ã‚¹ãƒ¬ãƒƒãƒ‰ã®å®Œäº†ã‚’å¾…ã¤
        for thread in threads:
            thread.join(timeout=30)

        # å°‘ãªãã¨ã‚‚ä¸€éƒ¨ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        completed_workers = sum(
            1 for completions in all_completion_signals if len(completions) > 0
        )
        assert completed_workers > 0, "ä¸¦è¡Œå®Ÿè¡Œã§ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“"

        print(f"âœ“ ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ç«¶åˆãƒ†ã‚¹ãƒˆå®Œäº†: {completed_workers}/3 ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå®Œäº†")

    def test_resource_cleanup_on_errors(self):
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ"""
        # ãƒªã‚½ãƒ¼ã‚¹ãƒªãƒ¼ã‚¯ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®ãƒ¢ãƒƒã‚¯
        opened_files = []
        original_open = open

        def tracking_open(*args, **kwargs):
            file_obj = original_open(*args, **kwargs)
            opened_files.append(file_obj)
            return file_obj

        with patch("builtins.open", side_effect=tracking_open):
            # ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼
            with patch.object(self.document_processor, "process_file") as mock_process:
                mock_process.side_effect = Exception("ãƒªã‚½ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ©ãƒ¼")

                worker = IndexingWorker(
                    str(self.test_folder),
                    self.document_processor,
                    self.index_manager,
                    self.file_watcher,
                )

                self._connect_error_signals(worker)
                worker.process_folder()

        # é–‹ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒé©åˆ‡ã«é–‰ã˜ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        for file_obj in opened_files:
            if not file_obj.closed:
                print(f"è­¦å‘Š: ãƒ•ã‚¡ã‚¤ãƒ«ãŒé–‰ã˜ã‚‰ã‚Œã¦ã„ã¾ã›ã‚“: {file_obj.name}")

        print("âœ“ ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆå®Œäº†")

    def test_error_logging_and_reporting(self):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²ãƒ»å ±å‘Šãƒ†ã‚¹ãƒˆ"""
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€ã‚’ç¢ºèª
        log_file = self.config.log_dir / "docmind.log"

        # ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹
        with patch.object(self.document_processor, "process_file") as mock_process:
            mock_process.side_effect = DocumentProcessingError("ãƒ­ã‚°ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ©ãƒ¼")

            worker = IndexingWorker(
                str(self.test_folder),
                self.document_processor,
                self.index_manager,
                self.file_watcher,
            )

            self._connect_error_signals(worker)
            worker.process_folder()

        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ãƒ©ãƒ¼ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        if log_file.exists():
            log_content = log_file.read_text(encoding="utf-8")
            assert (
                "ãƒ­ã‚°ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ©ãƒ¼" in log_content or "ERROR" in log_content
            ), "ã‚¨ãƒ©ãƒ¼ãŒãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

        # ã‚¨ãƒ©ãƒ¼ã‚·ã‚°ãƒŠãƒ«ãŒç™ºè¡Œã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert (
            len(self.error_signals) > 0 or len(self.completion_signals) > 0
        ), "ã‚¨ãƒ©ãƒ¼æƒ…å ±ãŒé©åˆ‡ã«å ±å‘Šã•ã‚Œã¦ã„ã¾ã›ã‚“"

        print("âœ“ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²ãƒ»å ±å‘Šãƒ†ã‚¹ãƒˆå®Œäº†")


@pytest.mark.integration
class TestDebuggingFeatures:
    """ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(autouse=True)
    def setup(self, test_config):
        """ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.config = test_config
        self.test_folder = Path(tempfile.mkdtemp())

        # ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        self._create_debug_test_files()

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.document_processor = DocumentProcessor()
        self.index_manager = IndexManager(str(self.config.index_dir))
        self.index_manager.create_index()
        self.file_watcher = Mock(spec=FileWatcher)

        yield

        if self.test_folder.exists():
            shutil.rmtree(self.test_folder)

    def _create_debug_test_files(self):
        """ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        # æ§˜ã€…ãªã‚¿ã‚¤ãƒ—ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        (self.test_folder / "debug1.txt").write_text(
            "ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«1", encoding="utf-8"
        )

        (self.test_folder / "debug2.md").write_text(
            "# ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆ\n\nMarkdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ", encoding="utf-8"
        )

        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        sub_dir = self.test_folder / "subdir"
        sub_dir.mkdir()
        (sub_dir / "debug3.txt").write_text(
            "ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‡ãƒãƒƒã‚°ãƒ•ã‚¡ã‚¤ãƒ«", encoding="utf-8"
        )

    def test_detailed_progress_tracking(self):
        """è©³ç´°é€²æ—è¿½è·¡ãƒ†ã‚¹ãƒˆ"""
        progress_history = []

        worker = IndexingWorker(
            str(self.test_folder),
            self.document_processor,
            self.index_manager,
            self.file_watcher,
        )

        # é€²æ—ã®è©³ç´°ã‚’è¨˜éŒ²
        def track_progress(message, current, total):
            progress_history.append(
                {
                    "timestamp": time.time(),
                    "message": message,
                    "current": current,
                    "total": total,
                    "percentage": (current / total * 100) if total > 0 else 0,
                }
            )

        worker.progress_updated.connect(track_progress)
        worker.process_folder()

        # é€²æ—å±¥æ­´ã‚’åˆ†æ
        assert len(progress_history) > 0, "é€²æ—å±¥æ­´ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

        # é€²æ—æ®µéšã®ç¢ºèª
        stages = set()
        for progress in progress_history:
            message = progress["message"]
            if "ã‚¹ã‚­ãƒ£ãƒ³" in message:
                stages.add("scanning")
            elif "å‡¦ç†ä¸­" in message:
                stages.add("processing")
            elif "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹" in message:
                stages.add("indexing")

        assert len(stages) >= 2, f"ååˆ†ãªé€²æ—æ®µéšãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“: {stages}"

        # é€²æ—ç‡ã®å¦¥å½“æ€§ç¢ºèª
        for progress in progress_history:
            assert (
                0 <= progress["percentage"] <= 100
            ), f"é€²æ—ç‡ãŒç¯„å›²å¤–ã§ã™: {progress['percentage']}%"

        print(f"âœ“ è©³ç´°é€²æ—è¿½è·¡ãƒ†ã‚¹ãƒˆå®Œäº†: {len(progress_history)}å€‹ã®é€²æ—è¨˜éŒ²")

    def test_file_processing_diagnostics(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†è¨ºæ–­ãƒ†ã‚¹ãƒˆ"""
        file_diagnostics = []

        worker = IndexingWorker(
            str(self.test_folder),
            self.document_processor,
            self.index_manager,
            self.file_watcher,
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®è©³ç´°ã‚’è¨˜éŒ²
        def track_file_processing(file_path, success, error_msg):
            file_info = {
                "file_path": file_path,
                "success": success,
                "error_msg": error_msg,
                "file_size": 0,
                "file_type": Path(file_path).suffix,
            }

            try:
                file_info["file_size"] = os.path.getsize(file_path)
            except:
                pass

            file_diagnostics.append(file_info)

        worker.file_processed.connect(track_file_processing)
        worker.process_folder()

        # è¨ºæ–­æƒ…å ±ã‚’åˆ†æ
        assert len(file_diagnostics) > 0, "ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†è¨ºæ–­ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

        successful_files = [f for f in file_diagnostics if f["success"]]
        failed_files = [f for f in file_diagnostics if not f["success"]]

        print("ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†è¨ºæ–­çµæœ:")
        print(f"  æˆåŠŸ: {len(successful_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"  å¤±æ•—: {len(failed_files)}ãƒ•ã‚¡ã‚¤ãƒ«")

        for file_info in file_diagnostics:
            status = "æˆåŠŸ" if file_info["success"] else "å¤±æ•—"
            print(
                f"  {status}: {Path(file_info['file_path']).name} "
                f"({file_info['file_size']}bytes, {file_info['file_type']})"
            )

        print("âœ“ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†è¨ºæ–­ãƒ†ã‚¹ãƒˆå®Œäº†")

    def test_performance_profiling(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        timing_data = {}

        # å‡¦ç†æ™‚é–“ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®ãƒ¢ãƒƒã‚¯
        original_process_file = self.document_processor.process_file

        def timed_process_file(file_path):
            start_time = time.time()
            try:
                result = original_process_file(file_path)
                processing_time = time.time() - start_time
                timing_data[file_path] = {
                    "processing_time": processing_time,
                    "success": True,
                    "file_size": (
                        os.path.getsize(file_path) if os.path.exists(file_path) else 0
                    ),
                }
                return result
            except Exception as e:
                processing_time = time.time() - start_time
                timing_data[file_path] = {
                    "processing_time": processing_time,
                    "success": False,
                    "error": str(e),
                    "file_size": (
                        os.path.getsize(file_path) if os.path.exists(file_path) else 0
                    ),
                }
                raise

        with patch.object(
            self.document_processor, "process_file", side_effect=timed_process_file
        ):
            worker = IndexingWorker(
                str(self.test_folder),
                self.document_processor,
                self.index_manager,
                self.file_watcher,
            )

            start_time = time.time()
            worker.process_folder()
            total_time = time.time() - start_time

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        if timing_data:
            processing_times = [
                data["processing_time"] for data in timing_data.values()
            ]
            file_sizes = [data["file_size"] for data in timing_data.values()]

            avg_processing_time = sum(processing_times) / len(processing_times)
            max_processing_time = max(processing_times)
            total_file_size = sum(file_sizes)

            print("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœ:")
            print(f"  ç·å‡¦ç†æ™‚é–“: {total_time:.3f}ç§’")
            print(f"  å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚é–“: {avg_processing_time:.3f}ç§’")
            print(f"  æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚é–“: {max_processing_time:.3f}ç§’")
            print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {total_file_size}bytes")
            print(f"  å‡¦ç†é€Ÿåº¦: {total_file_size/total_time:.1f}bytes/ç§’")

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ã®ç¢ºèª
            assert (
                avg_processing_time < 5.0
            ), f"å¹³å‡å‡¦ç†æ™‚é–“ãŒé•·ã™ãã¾ã™: {avg_processing_time:.3f}ç§’"

        print("âœ“ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Œäº†")

    def test_memory_usage_monitoring(self, memory_monitor):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–ãƒ†ã‚¹ãƒˆ"""
        memory_monitor.start()

        memory_snapshots = []

        worker = IndexingWorker(
            str(self.test_folder),
            self.document_processor,
            self.index_manager,
            self.file_watcher,
        )

        # é€²æ—ã«å¿œã˜ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è¨˜éŒ²
        def track_memory_usage(message, current, total):
            memory_usage = memory_monitor.get_current_memory()
            memory_snapshots.append(
                {
                    "stage": message,
                    "progress": f"{current}/{total}",
                    "memory_mb": memory_usage,
                }
            )

        worker.progress_updated.connect(track_memory_usage)
        worker.process_folder()

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ†æ
        if memory_snapshots:
            initial_memory = memory_snapshots[0]["memory_mb"]
            peak_memory = max(snapshot["memory_mb"] for snapshot in memory_snapshots)
            final_memory = memory_snapshots[-1]["memory_mb"]

            memory_increase = final_memory - initial_memory
            peak_increase = peak_memory - initial_memory

            print("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–çµæœ:")
            print(f"  åˆæœŸãƒ¡ãƒ¢ãƒª: {initial_memory:.2f}MB")
            print(f"  ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {peak_memory:.2f}MB")
            print(f"  æœ€çµ‚ãƒ¡ãƒ¢ãƒª: {final_memory:.2f}MB")
            print(f"  ãƒ¡ãƒ¢ãƒªå¢—åŠ : {memory_increase:.2f}MB")
            print(f"  ãƒ”ãƒ¼ã‚¯å¢—åŠ : {peak_increase:.2f}MB")

            # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®ç¢ºèª
            assert (
                memory_increase < 100
            ), f"ãƒ¡ãƒ¢ãƒªå¢—åŠ ãŒå¤§ãã™ãã¾ã™: {memory_increase:.2f}MB"

        print("âœ“ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–ãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
