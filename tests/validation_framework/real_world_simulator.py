# -*- coding: utf-8 -*-
"""
å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½

DocMindã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿéš›ã®ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã€
å…¸å‹çš„ãªæ—¥æ¬¡ã€é€±æ¬¡ã€æœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„ã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªã‚’åŒ…æ‹¬çš„ã«æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import time
import threading
import psutil
import gc
import random
import string
import os
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Callable
from unittest.mock import Mock, MagicMock
import tempfile
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import json
import logging

try:
    from .base_validator import BaseValidator, ValidationResult, ValidationConfig
    from .test_dataset_manager import TestDatasetManager, DatasetInfo
    from .memory_monitor import MemoryMonitor
    from .performance_monitor import PerformanceMonitor
    from .statistics_collector import StatisticsCollector
except ImportError:
    from base_validator import BaseValidator, ValidationResult, ValidationConfig
    from test_dataset_manager import TestDatasetManager, DatasetInfo
    from memory_monitor import MemoryMonitor
    from performance_monitor import PerformanceMonitor
    from statistics_collector import StatisticsCollector

# DocMindã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.core.search_manager import SearchManager
    from src.core.index_manager import IndexManager
    from src.core.embedding_manager import EmbeddingManager
    from src.core.document_processor import DocumentProcessor
    from src.data.database import DatabaseManager
    from src.data.models import Document, SearchResult, SearchType, FileType
    from src.utils.config import Config
except ImportError as e:
    print(f"DocMindã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")


class UsagePatternType(Enum):
    """ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—"""
    DAILY = "daily"
    WEEKLY = "weekly"
    MONTHLY = "monthly"
    INTENSIVE = "intensive"
    CASUAL = "casual"


class UserScenarioType(Enum):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—"""
    NEW_USER = "new_user"
    EXISTING_USER = "existing_user"
    POWER_USER = "power_user"
    BULK_PROCESSING = "bulk_processing"


class EdgeCaseType(Enum):
    """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—"""
    LARGE_FILES = "large_files"
    MANY_FILES = "many_files"
    SPECIAL_CHARACTERS = "special_characters"
    CORRUPTED_FILES = "corrupted_files"
    MEMORY_PRESSURE = "memory_pressure"
    DISK_PRESSURE = "disk_pressure"


@dataclass
class SimulationMetrics:
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    total_operations: int = 0
    successful_operations: int = 0
    failed_operations: int = 0
    average_response_time: float = 0.0
    peak_memory_usage_mb: float = 0.0
    peak_cpu_usage_percent: float = 0.0
    total_files_processed: int = 0
    total_searches_executed: int = 0
    errors: List[str] = field(default_factory=list)
    
    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡ã®è¨ˆç®—"""
        if self.total_operations == 0:
            return 0.0
        return (self.successful_operations / self.total_operations) * 100.0
    
    @property
    def duration_seconds(self) -> float:
        """å®Ÿè¡Œæ™‚é–“ã®è¨ˆç®—"""
        if self.end_time is None:
            return 0.0
        return (self.end_time - self.start_time).total_seconds()


@dataclass
class UsagePattern:
    """ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©"""
    name: str
    pattern_type: UsagePatternType
    operations_per_session: int
    session_duration_minutes: int
    search_frequency: float  # æ“ä½œã‚ãŸã‚Šã®æ¤œç´¢é »åº¦
    document_add_frequency: float  # æ“ä½œã‚ãŸã‚Šã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ é »åº¦
    concurrent_operations: int = 1
    break_duration_seconds: float = 1.0


class RealWorldSimulator(BaseValidator):
    """
    å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¯ãƒ©ã‚¹
    
    DocMindã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿéš›ã®ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã€
    å…¸å‹çš„ãªä½¿ç”¨ã‚·ãƒŠãƒªã‚ªã‚„ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’åŒ…æ‹¬çš„ã«æ¤œè¨¼ã—ã¾ã™ã€‚
    """
    
    def __init__(self, config: Optional[ValidationConfig] = None):
        """
        å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        
        Args:
            config: æ¤œè¨¼è¨­å®š
        """
        super().__init__(config)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†
        self.dataset_manager = TestDatasetManager()
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒ
        self.temp_dir = None
        self.test_config = None
        
        # DocMindã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.db_manager = None
        self.index_manager = None
        self.embedding_manager = None
        self.document_processor = None
        self.search_manager = None
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹
        self.simulation_active = False
        self.current_metrics = SimulationMetrics()
        self.simulation_threads: List[threading.Thread] = []
        
        # ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
        self.usage_patterns = self._define_usage_patterns()
        
        # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å®šç¾©
        self.edge_cases = self._define_edge_cases()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªå®šç¾©
        self.user_scenarios = self._define_user_scenarios()
        
        self.logger.info("å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¯ãƒ©ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    
    def setup_test_environment(self) -> None:
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.logger.info("å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™")
        
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        self.temp_dir = Path(tempfile.mkdtemp(prefix="docmind_realworld_test_"))
        
        # ãƒ†ã‚¹ãƒˆè¨­å®šã®ä½œæˆ
        class TestConfig:
            def __init__(self, temp_dir):
                self.data_dir = temp_dir / "data"
                self.database_file = temp_dir / "test.db"
                self.index_dir = temp_dir / "index"
                self.cache_dir = temp_dir / "cache"
                self.logs_dir = temp_dir / "logs"
                # è¨­å®šå€¤
                self.search_timeout = 5.0
                self.max_results = 100
                self.enable_semantic_search = True
                self.cache_size = 1000
                self.max_file_size_mb = 100
        
        self.test_config = TestConfig(self.temp_dir)
        
        # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        for dir_path in [
            self.test_config.data_dir, 
            self.test_config.index_dir, 
            self.test_config.cache_dir,
            self.test_config.logs_dir
        ]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # DocMindã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self._initialize_docmind_components()
        
        self.logger.info(f"ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†: {self.temp_dir}")
    
    def teardown_test_environment(self) -> None:
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.logger.info("å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã™")
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®åœæ­¢
        self.simulation_active = False
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…æ©Ÿ
        for thread in self.simulation_threads:
            if thread.is_alive():
                thread.join(timeout=5.0)
        
        # DocMindã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.db_manager:
            try:
                self.db_manager.close()
            except Exception as e:
                self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤
        if self.temp_dir and self.temp_dir.exists():
            try:
                shutil.rmtree(self.temp_dir, ignore_errors=True)
            except Exception as e:
                self.logger.warning(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            self.dataset_manager.cleanup_all_datasets()
        except Exception as e:
            self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ¡ãƒ¢ãƒªã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        gc.collect()
        
        self.logger.info("ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
    
    def test_daily_usage_pattern(self) -> None:
        """
        å…¸å‹çš„ãªæ—¥æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        
        è¦ä»¶9.1, 9.2: å®Ÿéš›ã®ä½¿ç”¨ã‚·ãƒŠãƒªã‚ªã§ã®å‹•ä½œç¢ºèª
        """
        self.logger.info("æ—¥æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹")
        
        pattern = self.usage_patterns[UsagePatternType.DAILY]
        metrics = self._execute_usage_pattern(pattern)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ã®ç¢ºèª
        self.assert_condition(
            metrics.success_rate >= 95.0,
            f"æ—¥æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æˆåŠŸç‡ãŒè¦ä»¶ã‚’ä¸‹å›ã‚‹: {metrics.success_rate:.1f}% < 95%"
        )
        
        self.assert_condition(
            metrics.average_response_time < 2.0,
            f"æ—¥æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¹³å‡å¿œç­”æ™‚é–“ãŒè¦ä»¶ã‚’è¶…é: {metrics.average_response_time:.2f}ç§’ > 2ç§’"
        )
        
        self.logger.info(f"æ—¥æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å®Œäº† - æˆåŠŸç‡: {metrics.success_rate:.1f}%, å¿œç­”æ™‚é–“: {metrics.average_response_time:.2f}ç§’")
    
    def test_weekly_usage_pattern(self) -> None:
        """
        å…¸å‹çš„ãªé€±æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        
        è¦ä»¶9.1, 9.2: ä¸­æœŸé–“ã®ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®å®‰å®šæ€§ç¢ºèª
        """
        self.logger.info("é€±æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹")
        
        pattern = self.usage_patterns[UsagePatternType.WEEKLY]
        metrics = self._execute_usage_pattern(pattern)
        
        # å®‰å®šæ€§è¦ä»¶ã®ç¢ºèª
        self.assert_condition(
            metrics.success_rate >= 90.0,
            f"é€±æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æˆåŠŸç‡ãŒè¦ä»¶ã‚’ä¸‹å›ã‚‹: {metrics.success_rate:.1f}% < 90%"
        )
        
        self.assert_condition(
            metrics.peak_memory_usage_mb < 2048.0,
            f"é€±æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒè¦ä»¶ã‚’è¶…é: {metrics.peak_memory_usage_mb:.1f}MB > 2048MB"
        )
        
        self.logger.info(f"é€±æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å®Œäº† - æˆåŠŸç‡: {metrics.success_rate:.1f}%, ãƒ¡ãƒ¢ãƒª: {metrics.peak_memory_usage_mb:.1f}MB")
    
    def test_monthly_usage_pattern(self) -> None:
        """
        å…¸å‹çš„ãªæœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        
        è¦ä»¶9.5: é•·æœŸé–“ä½¿ç”¨æ™‚ã®å®‰å®šæ€§ç¢ºèª
        """
        self.logger.info("æœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹")
        
        pattern = self.usage_patterns[UsagePatternType.MONTHLY]
        metrics = self._execute_usage_pattern(pattern)
        
        # é•·æœŸå®‰å®šæ€§è¦ä»¶ã®ç¢ºèª
        self.assert_condition(
            metrics.success_rate >= 85.0,
            f"æœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æˆåŠŸç‡ãŒè¦ä»¶ã‚’ä¸‹å›ã‚‹: {metrics.success_rate:.1f}% < 85%"
        )
        
        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®ç¢ºèª
        memory_growth_rate = (metrics.peak_memory_usage_mb - 500.0) / 500.0 * 100  # 500MBã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
        self.assert_condition(
            memory_growth_rate < 50.0,
            f"æœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒæ¤œå‡º: {memory_growth_rate:.1f}% > 50%"
        )
        
        self.logger.info(f"æœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å®Œäº† - æˆåŠŸç‡: {metrics.success_rate:.1f}%, ãƒ¡ãƒ¢ãƒªå¢—åŠ : {memory_growth_rate:.1f}%")
    
    def test_large_files_edge_case(self) -> None:
        """
        æ¥µç«¯ã«å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
        
        è¦ä»¶9.3: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã§ã®å‹•ä½œç¢ºèª
        """
        self.logger.info("å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
        
        # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
        large_files = self._generate_large_files()
        
        processing_results = []
        for file_path in large_files:
            start_time = time.time()
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®å®Ÿè¡Œ
                result = self._process_large_file(file_path)
                processing_time = time.time() - start_time
                
                processing_results.append({
                    'file_path': file_path,
                    'success': result is not None,
                    'processing_time': processing_time,
                    'file_size_mb': os.path.getsize(file_path) / (1024 * 1024)
                })
                
                # å‡¦ç†æ™‚é–“è¦ä»¶ã®ç¢ºèªï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ï¼‰
                file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
                max_time = min(60.0, file_size_mb * 2.0)  # æœ€å¤§60ç§’ã€ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºÃ—2ç§’
                
                self.assert_condition(
                    processing_time < max_time,
                    f"å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚é–“ãŒè¦ä»¶ã‚’è¶…é: {processing_time:.2f}ç§’ > {max_time:.2f}ç§’ (ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_mb:.1f}MB)"
                )
                
            except Exception as e:
                processing_results.append({
                    'file_path': file_path,
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                })
        
        # æˆåŠŸç‡ã®ç¢ºèª
        success_count = sum(1 for r in processing_results if r['success'])
        success_rate = (success_count / len(processing_results)) * 100 if processing_results else 0
        
        self.assert_condition(
            success_rate >= 80.0,
            f"å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æˆåŠŸç‡ãŒè¦ä»¶ã‚’ä¸‹å›ã‚‹: {success_rate:.1f}% < 80%"
        )
        
        self.logger.info(f"å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å®Œäº† - æˆåŠŸç‡: {success_rate:.1f}%")
    
    def test_many_files_edge_case(self) -> None:
        """
        å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
        
        è¦ä»¶9.3: å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã§ã®å‹•ä½œç¢ºèª
        """
        self.logger.info("å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
        
        # å¤šæ•°ã®å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        many_files = self._generate_many_small_files(count=1000)
        
        batch_size = 50
        processing_results = []
        
        for i in range(0, len(many_files), batch_size):
            batch = many_files[i:i + batch_size]
            batch_start = time.time()
            
            batch_success = 0
            for file_path in batch:
                try:
                    result = self._process_file_simple(file_path)
                    if result:
                        batch_success += 1
                except Exception as e:
                    self.logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            
            batch_time = time.time() - batch_start
            processing_results.append({
                'batch_size': len(batch),
                'success_count': batch_success,
                'processing_time': batch_time
            })
            
            # ãƒãƒƒãƒå‡¦ç†æ™‚é–“è¦ä»¶ã®ç¢ºèª
            self.assert_condition(
                batch_time < 30.0,
                f"ãƒãƒƒãƒå‡¦ç†æ™‚é–“ãŒè¦ä»¶ã‚’è¶…é: {batch_time:.2f}ç§’ > 30ç§’ (ãƒãƒƒãƒã‚µã‚¤ã‚º: {len(batch)})"
            )
        
        # å…¨ä½“ã®æˆåŠŸç‡ç¢ºèª
        total_files = sum(r['batch_size'] for r in processing_results)
        total_success = sum(r['success_count'] for r in processing_results)
        overall_success_rate = (total_success / total_files) * 100 if total_files > 0 else 0
        
        self.assert_condition(
            overall_success_rate >= 90.0,
            f"å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æˆåŠŸç‡ãŒè¦ä»¶ã‚’ä¸‹å›ã‚‹: {overall_success_rate:.1f}% < 90%"
        )
        
        self.logger.info(f"å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å®Œäº† - æˆåŠŸç‡: {overall_success_rate:.1f}% ({total_success}/{total_files})")
    
    def test_special_characters_edge_case(self) -> None:
        """
        ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
        
        è¦ä»¶9.3: ç‰¹æ®Šæ–‡å­—å‡¦ç†ã§ã®å‹•ä½œç¢ºèª
        """
        self.logger.info("ç‰¹æ®Šæ–‡å­—ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
        
        # ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
        special_files = self._generate_special_character_files()
        
        processing_results = []
        for file_info in special_files:
            file_path = file_info['path']
            char_type = file_info['type']
            
            try:
                start_time = time.time()
                result = self._process_file_simple(file_path)
                processing_time = time.time() - start_time
                
                processing_results.append({
                    'file_path': file_path,
                    'char_type': char_type,
                    'success': result is not None,
                    'processing_time': processing_time
                })
                
                # å‡¦ç†æ™‚é–“è¦ä»¶ã®ç¢ºèª
                self.assert_condition(
                    processing_time < 10.0,
                    f"ç‰¹æ®Šæ–‡å­—ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚é–“ãŒè¦ä»¶ã‚’è¶…é: {processing_time:.2f}ç§’ > 10ç§’ (æ–‡å­—ã‚¿ã‚¤ãƒ—: {char_type})"
                )
                
            except Exception as e:
                processing_results.append({
                    'file_path': file_path,
                    'char_type': char_type,
                    'success': False,
                    'error': str(e)
                })
        
        # æ–‡å­—ã‚¿ã‚¤ãƒ—åˆ¥æˆåŠŸç‡ã®ç¢ºèª
        char_types = set(r['char_type'] for r in processing_results)
        for char_type in char_types:
            type_results = [r for r in processing_results if r['char_type'] == char_type]
            success_count = sum(1 for r in type_results if r['success'])
            success_rate = (success_count / len(type_results)) * 100 if type_results else 0
            
            self.assert_condition(
                success_rate >= 85.0,
                f"ç‰¹æ®Šæ–‡å­—ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æˆåŠŸç‡ãŒè¦ä»¶ã‚’ä¸‹å›ã‚‹ ({char_type}): {success_rate:.1f}% < 85%"
            )
        
        self.logger.info("ç‰¹æ®Šæ–‡å­—ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å®Œäº†")
    
    def test_new_user_scenario(self) -> None:
        """
        æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªã®æ¤œè¨¼
        
        è¦ä»¶9.4: æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆå›ä½¿ç”¨ä½“é¨“
        """
        self.logger.info("æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
        
        scenario = self.user_scenarios[UserScenarioType.NEW_USER]
        metrics = self._execute_user_scenario(scenario)
        
        # æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦ä»¶ã®ç¢ºèª
        self.assert_condition(
            metrics.success_rate >= 95.0,
            f"æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªæˆåŠŸç‡ãŒè¦ä»¶ã‚’ä¸‹å›ã‚‹: {metrics.success_rate:.1f}% < 95%"
        )
        
        # åˆå›èµ·å‹•æ™‚é–“ã®ç¢ºèª
        self.assert_condition(
            metrics.average_response_time < 15.0,
            f"æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆå›èµ·å‹•æ™‚é–“ãŒè¦ä»¶ã‚’è¶…é: {metrics.average_response_time:.2f}ç§’ > 15ç§’"
        )
        
        self.logger.info(f"æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªå®Œäº† - æˆåŠŸç‡: {metrics.success_rate:.1f}%")
    
    def test_existing_user_scenario(self) -> None:
        """
        æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªã®æ¤œè¨¼
        
        è¦ä»¶9.4: æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ—¥å¸¸ä½¿ç”¨ä½“é¨“
        """
        self.logger.info("æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        self._prepare_existing_user_data()
        
        scenario = self.user_scenarios[UserScenarioType.EXISTING_USER]
        metrics = self._execute_user_scenario(scenario)
        
        # æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦ä»¶ã®ç¢ºèª
        self.assert_condition(
            metrics.success_rate >= 98.0,
            f"æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªæˆåŠŸç‡ãŒè¦ä»¶ã‚’ä¸‹å›ã‚‹: {metrics.success_rate:.1f}% < 98%"
        )
        
        self.assert_condition(
            metrics.average_response_time < 3.0,
            f"æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œå¿œç­”æ™‚é–“ãŒè¦ä»¶ã‚’è¶…é: {metrics.average_response_time:.2f}ç§’ > 3ç§’"
        )
        
        self.logger.info(f"æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªå®Œäº† - æˆåŠŸç‡: {metrics.success_rate:.1f}%")
    
    def test_bulk_processing_scenario(self) -> None:
        """
        å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŠãƒªã‚ªã®æ¤œè¨¼
        
        è¦ä»¶9.4: å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã§ã®å‹•ä½œç¢ºèª
        """
        self.logger.info("å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
        
        scenario = self.user_scenarios[UserScenarioType.BULK_PROCESSING]
        metrics = self._execute_user_scenario(scenario)
        
        # å¤§é‡å‡¦ç†è¦ä»¶ã®ç¢ºèª
        self.assert_condition(
            metrics.success_rate >= 85.0,
            f"å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŠãƒªã‚ªæˆåŠŸç‡ãŒè¦ä»¶ã‚’ä¸‹å›ã‚‹: {metrics.success_rate:.1f}% < 85%"
        )
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ç¢ºèª
        self.assert_condition(
            metrics.peak_memory_usage_mb < 3072.0,  # 3GB
            f"å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒè¦ä»¶ã‚’è¶…é: {metrics.peak_memory_usage_mb:.1f}MB > 3072MB"
        )
        
        self.logger.info(f"å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŠãƒªã‚ªå®Œäº† - æˆåŠŸç‡: {metrics.success_rate:.1f}%, ãƒ¡ãƒ¢ãƒª: {metrics.peak_memory_usage_mb:.1f}MB")
    
    def _define_usage_patterns(self) -> Dict[UsagePatternType, UsagePattern]:
        """ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©"""
        return {
            UsagePatternType.DAILY: UsagePattern(
                name="æ—¥æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³",
                pattern_type=UsagePatternType.DAILY,
                operations_per_session=50,
                session_duration_minutes=30,
                search_frequency=0.7,
                document_add_frequency=0.1,
                concurrent_operations=1,
                break_duration_seconds=2.0
            ),
            UsagePatternType.WEEKLY: UsagePattern(
                name="é€±æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³",
                pattern_type=UsagePatternType.WEEKLY,
                operations_per_session=200,
                session_duration_minutes=120,
                search_frequency=0.6,
                document_add_frequency=0.2,
                concurrent_operations=2,
                break_duration_seconds=1.0
            ),
            UsagePatternType.MONTHLY: UsagePattern(
                name="æœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³",
                pattern_type=UsagePatternType.MONTHLY,
                operations_per_session=500,
                session_duration_minutes=300,
                search_frequency=0.5,
                document_add_frequency=0.3,
                concurrent_operations=3,
                break_duration_seconds=0.5
            )
        }
    
    def _define_edge_cases(self) -> Dict[EdgeCaseType, Dict[str, Any]]:
        """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®å®šç¾©"""
        return {
            EdgeCaseType.LARGE_FILES: {
                'name': 'å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«',
                'file_sizes_mb': [50, 100, 200, 500],
                'file_count': 5
            },
            EdgeCaseType.MANY_FILES: {
                'name': 'å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«',
                'file_count': 1000,
                'file_size_kb': 10
            },
            EdgeCaseType.SPECIAL_CHARACTERS: {
                'name': 'ç‰¹æ®Šæ–‡å­—',
                'character_sets': ['emoji', 'unicode', 'japanese', 'symbols']
            }
        }
    
    def _define_user_scenarios(self) -> Dict[UserScenarioType, Dict[str, Any]]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªã®å®šç¾©"""
        return {
            UserScenarioType.NEW_USER: {
                'name': 'æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼',
                'operations': ['startup', 'folder_selection', 'initial_indexing', 'first_search'],
                'expected_duration_minutes': 10
            },
            UserScenarioType.EXISTING_USER: {
                'name': 'æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼',
                'operations': ['startup', 'search', 'add_document', 'search_again'],
                'expected_duration_minutes': 5
            },
            UserScenarioType.BULK_PROCESSING: {
                'name': 'å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†',
                'operations': ['startup', 'bulk_add', 'bulk_index', 'performance_search'],
                'expected_duration_minutes': 60
            }
        }
    
    def _initialize_docmind_components(self) -> None:
        """DocMindã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            self.db_manager = DatabaseManager(str(self.test_config.database_file))
            self.db_manager.initialize()
            
            self.index_manager = IndexManager(str(self.test_config.index_dir))
            self.index_manager.create_index()
            
            self.embedding_manager = EmbeddingManager()
            self.document_processor = DocumentProcessor()
            
            self.search_manager = SearchManager(
                self.index_manager,
                self.embedding_manager
            )
            
            self.logger.info("DocMindã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
            
        except Exception as e:
            self.logger.warning(f"DocMindã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ (ãƒ¢ãƒƒã‚¯ä½¿ç”¨): {e}")
            # ãƒ¢ãƒƒã‚¯ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ä½œæˆ
            self.db_manager = Mock()
            self.index_manager = Mock()
            self.embedding_manager = Mock()
            self.document_processor = Mock()
            self.search_manager = Mock()
    
    def _execute_usage_pattern(self, pattern: UsagePattern) -> SimulationMetrics:
        """ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿè¡Œ"""
        self.logger.info(f"ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè¡Œé–‹å§‹: {pattern.name}")
        
        metrics = SimulationMetrics()
        self.simulation_active = True
        
        # ãƒ¡ãƒ¢ãƒªãƒ»CPUç›£è¦–ã®é–‹å§‹
        memory_monitor = MemoryMonitor()
        memory_monitor.start_monitoring()
        
        response_times = []
        
        try:
            for i in range(pattern.operations_per_session):
                if not self.simulation_active:
                    break
                
                operation_start = time.time()
                
                # æ“ä½œã®å®Ÿè¡Œ
                success = self._execute_random_operation(
                    pattern.search_frequency,
                    pattern.document_add_frequency
                )
                
                operation_time = time.time() - operation_start
                response_times.append(operation_time)
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
                metrics.total_operations += 1
                if success:
                    metrics.successful_operations += 1
                else:
                    metrics.failed_operations += 1
                
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®è¨˜éŒ²
                current_memory = memory_monitor.get_current_memory()
                if current_memory > metrics.peak_memory_usage_mb:
                    metrics.peak_memory_usage_mb = current_memory
                
                # CPUä½¿ç”¨ç‡ã®è¨˜éŒ²
                cpu_usage = psutil.cpu_percent(interval=0.1)
                if cpu_usage > metrics.peak_cpu_usage_percent:
                    metrics.peak_cpu_usage_percent = cpu_usage
                
                # ä¼‘æ†©
                time.sleep(pattern.break_duration_seconds)
            
            # å¹³å‡å¿œç­”æ™‚é–“ã®è¨ˆç®—
            if response_times:
                metrics.average_response_time = sum(response_times) / len(response_times)
            
        except Exception as e:
            metrics.errors.append(str(e))
            self.logger.error(f"ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        
        finally:
            memory_monitor.stop_monitoring()
            metrics.end_time = datetime.now()
            self.simulation_active = False
        
        self.logger.info(f"ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè¡Œå®Œäº†: {pattern.name}")
        return metrics
    
    def _execute_user_scenario(self, scenario: Dict[str, Any]) -> SimulationMetrics:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªã®å®Ÿè¡Œ"""
        self.logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œé–‹å§‹: {scenario['name']}")
        
        metrics = SimulationMetrics()
        
        try:
            for operation in scenario['operations']:
                operation_start = time.time()
                success = self._execute_scenario_operation(operation)
                operation_time = time.time() - operation_start
                
                metrics.total_operations += 1
                if success:
                    metrics.successful_operations += 1
                else:
                    metrics.failed_operations += 1
                
                # å¿œç­”æ™‚é–“ã®è¨˜éŒ²
                if metrics.average_response_time == 0:
                    metrics.average_response_time = operation_time
                else:
                    metrics.average_response_time = (metrics.average_response_time + operation_time) / 2
            
        except Exception as e:
            metrics.errors.append(str(e))
            self.logger.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        
        finally:
            metrics.end_time = datetime.now()
        
        self.logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œå®Œäº†: {scenario['name']}")
        return metrics
    
    def _execute_random_operation(self, search_freq: float, doc_add_freq: float) -> bool:
        """ãƒ©ãƒ³ãƒ€ãƒ æ“ä½œã®å®Ÿè¡Œ"""
        rand = random.random()
        
        try:
            if rand < search_freq:
                # æ¤œç´¢æ“ä½œ
                return self._perform_search_operation()
            elif rand < search_freq + doc_add_freq:
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ æ“ä½œ
                return self._perform_document_add_operation()
            else:
                # ãã®ä»–ã®æ“ä½œï¼ˆè¨­å®šå¤‰æ›´ã€ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã©ï¼‰
                return self._perform_misc_operation()
        except Exception as e:
            self.logger.warning(f"æ“ä½œå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _execute_scenario_operation(self, operation: str) -> bool:
        """ã‚·ãƒŠãƒªã‚ªæ“ä½œã®å®Ÿè¡Œ"""
        try:
            if operation == 'startup':
                return self._perform_startup_operation()
            elif operation == 'folder_selection':
                return self._perform_folder_selection_operation()
            elif operation == 'initial_indexing':
                return self._perform_initial_indexing_operation()
            elif operation == 'first_search':
                return self._perform_search_operation()
            elif operation == 'search':
                return self._perform_search_operation()
            elif operation == 'add_document':
                return self._perform_document_add_operation()
            elif operation == 'search_again':
                return self._perform_search_operation()
            elif operation == 'bulk_add':
                return self._perform_bulk_add_operation()
            elif operation == 'bulk_index':
                return self._perform_bulk_index_operation()
            elif operation == 'performance_search':
                return self._perform_performance_search_operation()
            else:
                self.logger.warning(f"æœªçŸ¥ã®æ“ä½œ: {operation}")
                return False
        except Exception as e:
            self.logger.warning(f"ã‚·ãƒŠãƒªã‚ªæ“ä½œã‚¨ãƒ©ãƒ¼ ({operation}): {e}")
            return False
    
    def _perform_search_operation(self) -> bool:
        """æ¤œç´¢æ“ä½œã®å®Ÿè¡Œ"""
        queries = ["ãƒ†ã‚¹ãƒˆ", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ", "Python", "æ¤œç´¢", "ãƒ‡ãƒ¼ã‚¿"]
        query = random.choice(queries)
        
        if self.search_manager:
            try:
                results = self.search_manager.search(query, SearchType.FULL_TEXT)
                return isinstance(results, list)
            except Exception:
                return False
        return True  # ãƒ¢ãƒƒã‚¯æ™‚ã¯æˆåŠŸã¨ã™ã‚‹
    
    def _perform_document_add_operation(self) -> bool:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ æ“ä½œã®å®Ÿè¡Œ"""
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
        test_file = self.test_config.data_dir / f"test_{random.randint(1000, 9999)}.txt"
        test_content = f"ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {datetime.now()}"
        
        try:
            test_file.write_text(test_content, encoding='utf-8')
            
            if self.document_processor:
                doc = self.document_processor.process_file(str(test_file))
                if doc and self.db_manager:
                    self.db_manager.add_document(doc)
                if doc and self.index_manager:
                    self.index_manager.add_document(doc)
            
            return True
        except Exception:
            return False
    
    def _perform_misc_operation(self) -> bool:
        """ãã®ä»–ã®æ“ä½œã®å®Ÿè¡Œ"""
        # è¨­å®šå¤‰æ›´ã€ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ãƒ•ã‚©ãƒ«ãƒ€é¸æŠãªã©ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        time.sleep(0.1)  # è»½ã„å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        return True
    
    def _perform_startup_operation(self) -> bool:
        """èµ·å‹•æ“ä½œã®å®Ÿè¡Œ"""
        # èµ·å‹•å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        time.sleep(1.0)
        return True
    
    def _perform_folder_selection_operation(self) -> bool:
        """ãƒ•ã‚©ãƒ«ãƒ€é¸æŠæ“ä½œã®å®Ÿè¡Œ"""
        # ãƒ•ã‚©ãƒ«ãƒ€é¸æŠã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        return True
    
    def _perform_initial_indexing_operation(self) -> bool:
        """åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–æ“ä½œã®å®Ÿè¡Œ"""
        # åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        time.sleep(2.0)
        return True
    
    def _perform_bulk_add_operation(self) -> bool:
        """ä¸€æ‹¬è¿½åŠ æ“ä½œã®å®Ÿè¡Œ"""
        # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€æ‹¬è¿½åŠ 
        for i in range(10):
            if not self._perform_document_add_operation():
                return False
        return True
    
    def _perform_bulk_index_operation(self) -> bool:
        """ä¸€æ‹¬ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–æ“ä½œã®å®Ÿè¡Œ"""
        # ä¸€æ‹¬ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        time.sleep(5.0)
        return True
    
    def _perform_performance_search_operation(self) -> bool:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œç´¢æ“ä½œã®å®Ÿè¡Œ"""
        # è¤‡æ•°ã®æ¤œç´¢ã‚’é€£ç¶šå®Ÿè¡Œ
        for _ in range(5):
            if not self._perform_search_operation():
                return False
        return True
    
    def _generate_large_files(self) -> List[str]:
        """å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ"""
        large_files = []
        sizes_mb = [50, 100, 200]  # ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
        
        for size_mb in sizes_mb:
            file_path = self.test_config.data_dir / f"large_file_{size_mb}mb.txt"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ç”Ÿæˆ
            content_size = size_mb * 1024 * 1024  # ãƒã‚¤ãƒˆå˜ä½
            chunk_size = 1024  # 1KBãšã¤æ›¸ãè¾¼ã¿
            
            with open(file_path, 'w', encoding='utf-8') as f:
                written = 0
                while written < content_size:
                    chunk = ''.join(random.choices(string.ascii_letters + string.digits + ' \n', k=chunk_size))
                    f.write(chunk)
                    written += len(chunk.encode('utf-8'))
            
            large_files.append(str(file_path))
        
        return large_files
    
    def _generate_many_small_files(self, count: int) -> List[str]:
        """å¤šæ•°ã®å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ"""
        files = []
        
        for i in range(count):
            file_path = self.test_config.data_dir / f"small_file_{i:04d}.txt"
            content = f"å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ« {i}: {random.choice(['ãƒ†ã‚¹ãƒˆ', 'ãƒ‡ãƒ¼ã‚¿', 'å†…å®¹', 'æƒ…å ±'])}"
            
            file_path.write_text(content, encoding='utf-8')
            files.append(str(file_path))
        
        return files
    
    def _generate_special_character_files(self) -> List[Dict[str, Any]]:
        """ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ"""
        special_files = []
        
        # çµµæ–‡å­—ãƒ•ã‚¡ã‚¤ãƒ«
        emoji_file = self.test_config.data_dir / "emoji_file.txt"
        emoji_content = "çµµæ–‡å­—ãƒ†ã‚¹ãƒˆ ğŸ˜€ğŸ˜ƒğŸ˜„ğŸ˜ğŸ˜†ğŸ˜…ğŸ˜‚ğŸ¤£"
        emoji_file.write_text(emoji_content, encoding='utf-8')
        special_files.append({'path': str(emoji_file), 'type': 'emoji'})
        
        # Unicodeæ–‡å­—ãƒ•ã‚¡ã‚¤ãƒ«
        unicode_file = self.test_config.data_dir / "unicode_file.txt"
        unicode_content = "Unicodeæ–‡å­—: Î±Î²Î³Î´Îµ Ã±Ã¡Ã©Ã­Ã³Ãº Ã§Ã¼Ã¶Ã¤ÃŸ"
        unicode_file.write_text(unicode_content, encoding='utf-8')
        special_files.append({'path': str(unicode_file), 'type': 'unicode'})
        
        # æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«
        japanese_file = self.test_config.data_dir / "japanese_file.txt"
        japanese_content = "æ—¥æœ¬èªãƒ†ã‚¹ãƒˆï¼šã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã€è¨˜å·ï¼ï¼Ÿ"
        japanese_file.write_text(japanese_content, encoding='utf-8')
        special_files.append({'path': str(japanese_file), 'type': 'japanese'})
        
        # è¨˜å·ãƒ•ã‚¡ã‚¤ãƒ«
        symbols_file = self.test_config.data_dir / "symbols_file.txt"
        symbols_content = "è¨˜å·ãƒ†ã‚¹ãƒˆ: @#$%^&*()_+-=[]{}|;':\",./<>?"
        symbols_file.write_text(symbols_content, encoding='utf-8')
        special_files.append({'path': str(symbols_file), 'type': 'symbols'})
        
        return special_files
    
    def _process_large_file(self, file_path: str) -> Optional[Document]:
        """å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
        if self.document_processor:
            try:
                return self.document_processor.process_file(file_path)
            except Exception as e:
                self.logger.warning(f"å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                return None
        
        # ãƒ¢ãƒƒã‚¯å‡¦ç†
        time.sleep(random.uniform(1.0, 5.0))
        return Mock()
    
    def _process_file_simple(self, file_path: str) -> Optional[Document]:
        """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†"""
        if self.document_processor:
            try:
                return self.document_processor.process_file(file_path)
            except Exception as e:
                self.logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                return None
        
        # ãƒ¢ãƒƒã‚¯å‡¦ç†
        time.sleep(random.uniform(0.1, 0.5))
        return Mock()
    
    def _prepare_existing_user_data(self) -> None:
        """æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™"""
        # æ—¢å­˜ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¨¡æ“¬
        for i in range(10):
            self._perform_document_add_operation()


if __name__ == "__main__":
    # å˜ä½“ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    simulator = RealWorldSimulator()
    
    try:
        simulator.setup_test_environment()
        results = simulator.run_validation()
        
        print("\n=== å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼çµæœ ===")
        for result in results:
            status = "âœ“" if result.success else "âœ—"
            print(f"{status} {result.test_name}: {result.execution_time:.2f}ç§’")
            if not result.success:
                print(f"  ã‚¨ãƒ©ãƒ¼: {result.error_message}")
        
        print(f"\nåˆæ ¼ç‡: {sum(1 for r in results if r.success)}/{len(results)}")
        
    finally:
        simulator.teardown_test_environment()
        simulator.cleanup()