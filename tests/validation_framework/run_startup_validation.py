#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ¤œè¨¼ã®å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ApplicationStartupValidatorã‚’ä½¿ç”¨ã—ã¦ã€DocMindã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®
èµ·å‹•ãƒ—ãƒ­ã‚»ã‚¹ã‚’åŒ…æ‹¬çš„ã«æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import sys
import logging
from pathlib import Path
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from application_startup_validator import ApplicationStartupValidator
from base_validator import ValidationConfig


def generate_simple_report(results, stats, total_tests, successful_tests, failed_tests):
    """ç°¡å˜ãªMarkdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    report = f"""# DocMind ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ

## å®Ÿè¡Œæ¦‚è¦
- å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}
- æˆåŠŸ: {successful_tests}
- å¤±æ•—: {failed_tests}
- æˆåŠŸç‡: {(successful_tests/total_tests)*100:.1f}%

## ãƒ†ã‚¹ãƒˆçµæœè©³ç´°

"""
    
    for result in results:
        status = "âœ… æˆåŠŸ" if result.success else "âŒ å¤±æ•—"
        report += f"### {result.test_name}\n"
        report += f"- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}\n"
        report += f"- å®Ÿè¡Œæ™‚é–“: {result.execution_time:.3f}ç§’\n"
        report += f"- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {result.memory_usage:.1f}MB\n"
        
        if not result.success and result.error_message:
            report += f"- ã‚¨ãƒ©ãƒ¼: {result.error_message}\n"
        
        report += "\n"
    
    if stats:
        report += "## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ\n\n"
        for key, value in stats.items():
            if isinstance(value, float):
                report += f"- {key}: {value:.3f}\n"
            else:
                report += f"- {key}: {value}\n"
    
    return report


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("DocMind ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ¤œè¨¼")
    print("=" * 60)
    print(f"å®Ÿè¡Œé–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # æ¤œè¨¼è¨­å®š
    config = ValidationConfig(
        enable_performance_monitoring=True,
        enable_memory_monitoring=True,
        enable_error_injection=True,
        max_execution_time=30.0,
        max_memory_usage=1024.0,
        log_level="INFO"
    )
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–
    validator = ApplicationStartupValidator(config)
    
    try:
        # ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        print("ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ã„ã¾ã™...")
        validator.setup_test_environment()
        print(f"ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {validator.temp_dir}")
        print()
        
        # æ¤œè¨¼ã®å®Ÿè¡Œ
        print("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...")
        print("-" * 40)
        
        # å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®šç¾©
        test_methods = [
            'test_startup_time_requirement',
            'test_directory_creation', 
            'test_config_initialization',
            'test_logging_system_initialization',
            'test_database_initialization',
            'test_startup_error_recovery',
            'test_startup_error_injection'
        ]
        
        # æ¤œè¨¼å®Ÿè¡Œ
        results = validator.run_validation(test_methods)
        
        # çµæœã®è¡¨ç¤º
        print("\n" + "=" * 60)
        print("æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        
        total_tests = len(results)
        successful_tests = sum(1 for r in results if r.success)
        failed_tests = total_tests - successful_tests
        
        print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        print(f"æˆåŠŸ: {successful_tests}")
        print(f"å¤±æ•—: {failed_tests}")
        print(f"æˆåŠŸç‡: {(successful_tests/total_tests)*100:.1f}%")
        print()
        
        # å€‹åˆ¥ãƒ†ã‚¹ãƒˆçµæœã®è¡¨ç¤º
        print("å€‹åˆ¥ãƒ†ã‚¹ãƒˆçµæœ:")
        print("-" * 40)
        
        for result in results:
            status = "âœ“ æˆåŠŸ" if result.success else "âœ— å¤±æ•—"
            print(f"{status} | {result.test_name}")
            print(f"    å®Ÿè¡Œæ™‚é–“: {result.execution_time:.3f}ç§’")
            print(f"    ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {result.memory_usage:.1f}MB")
            
            if not result.success and result.error_message:
                print(f"    ã‚¨ãƒ©ãƒ¼: {result.error_message}")
            print()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã®è¡¨ç¤º
        stats = validator.get_statistics_summary()
        if stats:
            print("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ:")
            print("-" * 40)
            for key, value in stats.items():
                if isinstance(value, float):
                    print(f"{key}: {value:.3f}")
                else:
                    print(f"{key}: {value}")
            print()
        
        # è¦ä»¶é©åˆæ€§ã®ç¢ºèª
        print("è¦ä»¶é©åˆæ€§ãƒã‚§ãƒƒã‚¯:")
        print("-" * 40)
        
        # èµ·å‹•æ™‚é–“è¦ä»¶ï¼ˆ10ç§’ä»¥å†…ï¼‰
        startup_result = next((r for r in results if 'startup_time' in r.test_name), None)
        if startup_result:
            startup_ok = startup_result.execution_time <= 10.0
            print(f"èµ·å‹•æ™‚é–“è¦ä»¶ (â‰¤10ç§’): {'âœ“' if startup_ok else 'âœ—'} {startup_result.execution_time:.2f}ç§’")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¦ä»¶ï¼ˆ2GBä»¥ä¸‹ï¼‰
        max_memory = max((r.memory_usage for r in results), default=0)
        memory_ok = max_memory <= 2048.0
        print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¦ä»¶ (â‰¤2GB): {'âœ“' if memory_ok else 'âœ—'} {max_memory:.1f}MB")
        
        # å…¨ä½“çš„ãªæˆåŠŸç‡è¦ä»¶ï¼ˆ90%ä»¥ä¸Šï¼‰
        success_rate_ok = (successful_tests / total_tests) >= 0.9
        print(f"æˆåŠŸç‡è¦ä»¶ (â‰¥90%): {'âœ“' if success_rate_ok else 'âœ—'} {(successful_tests/total_tests)*100:.1f}%")
        
        print()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        
        # ç°¡å˜ãªMarkdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        report_content = generate_simple_report(results, stats, total_tests, successful_tests, failed_tests)
        report_file = validator.temp_dir / "startup_validation_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_file}")
        
        # æœ€çµ‚åˆ¤å®š
        print("\n" + "=" * 60)
        overall_success = failed_tests == 0 and startup_ok and memory_ok and success_rate_ok
        
        if overall_success:
            print("ğŸ‰ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ¤œè¨¼: åˆæ ¼")
            print("ã™ã¹ã¦ã®è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã™ã€‚")
            exit_code = 0
        else:
            print("âŒ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ¤œè¨¼: ä¸åˆæ ¼")
            print("ä¸€éƒ¨ã®è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚è©³ç´°ã¯ä¸Šè¨˜ã®çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            exit_code = 1
        
        print("=" * 60)
        
        return exit_code
        
    except Exception as e:
        print(f"\nâŒ æ¤œè¨¼å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logging.exception("æ¤œè¨¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
        return 1
        
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            validator.teardown_test_environment()
            validator.cleanup()
            print("\nã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            print(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)