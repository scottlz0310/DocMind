#!/usr/bin/env python3
"""
å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

DocMindã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã‚’å®Ÿè¡Œã—ã€
å…¸å‹çš„ãªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from tests.validation_framework.base_validator import ValidationConfig
    from tests.validation_framework.real_world_simulator import RealWorldSimulator
    from tests.validation_framework.validation_reporter import ValidationReporter
except ImportError as e:
    print(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    sys.exit(1)


def setup_logging(log_level: str = "INFO", log_file: str = None) -> None:
    """ãƒ­ã‚°è¨­å®šã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'

    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®è¨­å®š
    numeric_level = getattr(logging, log_level.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError(f'ç„¡åŠ¹ãªãƒ­ã‚°ãƒ¬ãƒ™ãƒ«: {log_level}')

    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=numeric_level,
        format=log_format,
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã®è¿½åŠ 
    if log_file:
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setFormatter(logging.Formatter(log_format))
        logging.getLogger().addHandler(file_handler)


def create_validation_config(args) -> ValidationConfig:
    """æ¤œè¨¼è¨­å®šã®ä½œæˆ"""
    return ValidationConfig(
        enable_performance_monitoring=args.enable_performance,
        enable_memory_monitoring=args.enable_memory,
        enable_error_injection=args.enable_error_injection,
        max_execution_time=args.max_execution_time,
        max_memory_usage=args.max_memory_usage,
        log_level=args.log_level,
        output_directory=args.output_dir
    )


def run_usage_pattern_tests(simulator: RealWorldSimulator, patterns: list) -> dict:
    """ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    results = {}

    if not patterns or 'daily' in patterns:
        print("\n=== æ—¥æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ ===")
        try:
            simulator.test_daily_usage_pattern()
            results['daily'] = {'status': 'success', 'message': 'æ—¥æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†'}
        except Exception as e:
            results['daily'] = {'status': 'failed', 'message': str(e)}
            print(f"æ—¥æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    if not patterns or 'weekly' in patterns:
        print("\n=== é€±æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ ===")
        try:
            simulator.test_weekly_usage_pattern()
            results['weekly'] = {'status': 'success', 'message': 'é€±æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†'}
        except Exception as e:
            results['weekly'] = {'status': 'failed', 'message': str(e)}
            print(f"é€±æ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    if not patterns or 'monthly' in patterns:
        print("\n=== æœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ ===")
        try:
            simulator.test_monthly_usage_pattern()
            results['monthly'] = {'status': 'success', 'message': 'æœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†'}
        except Exception as e:
            results['monthly'] = {'status': 'failed', 'message': str(e)}
            print(f"æœˆæ¬¡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    return results


def run_edge_case_tests(simulator: RealWorldSimulator, edge_cases: list) -> dict:
    """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    results = {}

    if not edge_cases or 'large_files' in edge_cases:
        print("\n=== å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ ===")
        try:
            simulator.test_large_files_edge_case()
            results['large_files'] = {'status': 'success', 'message': 'å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆå®Œäº†'}
        except Exception as e:
            results['large_files'] = {'status': 'failed', 'message': str(e)}
            print(f"å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    if not edge_cases or 'many_files' in edge_cases:
        print("\n=== å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ ===")
        try:
            simulator.test_many_files_edge_case()
            results['many_files'] = {'status': 'success', 'message': 'å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆå®Œäº†'}
        except Exception as e:
            results['many_files'] = {'status': 'failed', 'message': str(e)}
            print(f"å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    if not edge_cases or 'special_chars' in edge_cases:
        print("\n=== ç‰¹æ®Šæ–‡å­—ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ ===")
        try:
            simulator.test_special_characters_edge_case()
            results['special_chars'] = {'status': 'success', 'message': 'ç‰¹æ®Šæ–‡å­—ãƒ†ã‚¹ãƒˆå®Œäº†'}
        except Exception as e:
            results['special_chars'] = {'status': 'failed', 'message': str(e)}
            print(f"ç‰¹æ®Šæ–‡å­—ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    return results


def run_user_scenario_tests(simulator: RealWorldSimulator, scenarios: list) -> dict:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    results = {}

    if not scenarios or 'new_user' in scenarios:
        print("\n=== æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ ===")
        try:
            simulator.test_new_user_scenario()
            results['new_user'] = {'status': 'success', 'message': 'æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå®Œäº†'}
        except Exception as e:
            results['new_user'] = {'status': 'failed', 'message': str(e)}
            print(f"æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    if not scenarios or 'existing_user' in scenarios:
        print("\n=== æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ ===")
        try:
            simulator.test_existing_user_scenario()
            results['existing_user'] = {'status': 'success', 'message': 'æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå®Œäº†'}
        except Exception as e:
            results['existing_user'] = {'status': 'failed', 'message': str(e)}
            print(f"æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    if not scenarios or 'bulk_processing' in scenarios:
        print("\n=== å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ ===")
        try:
            simulator.test_bulk_processing_scenario()
            results['bulk_processing'] = {'status': 'success', 'message': 'å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå®Œäº†'}
        except Exception as e:
            results['bulk_processing'] = {'status': 'failed', 'message': str(e)}
            print(f"å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    return results


def save_results(results: dict, output_file: str) -> None:
    """çµæœã®ä¿å­˜"""
    try:
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # çµæœã®ä¿å­˜
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)

        print(f"\næ¤œè¨¼çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")

    except Exception as e:
        print(f"çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


def print_summary(results: dict) -> None:
    """çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º"""
    print("\n" + "="*60)
    print("å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
    print("="*60)

    total_tests = 0
    passed_tests = 0

    for category, tests in results.items():
        if category == 'summary':
            continue

        print(f"\nã€{category.upper()}ã€‘")
        for test_name, test_result in tests.items():
            status_symbol = "âœ“" if test_result['status'] == 'success' else "âœ—"
            print(f"  {status_symbol} {test_name}: {test_result['message']}")

            total_tests += 1
            if test_result['status'] == 'success':
                passed_tests += 1

    # å…¨ä½“ã‚µãƒãƒªãƒ¼
    success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
    print("\nã€å…¨ä½“çµæœã€‘")
    print(f"  åˆæ ¼: {passed_tests}/{total_tests} ({success_rate:.1f}%)")

    if success_rate >= 90:
        print("  ğŸ‰ å„ªç§€ãªçµæœã§ã™ï¼")
    elif success_rate >= 75:
        print("  ğŸ‘ è‰¯å¥½ãªçµæœã§ã™")
    elif success_rate >= 50:
        print("  âš ï¸  æ”¹å–„ãŒå¿…è¦ã§ã™")
    else:
        print("  âŒ é‡å¤§ãªå•é¡ŒãŒã‚ã‚Šã¾ã™")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="DocMindå®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
  python run_real_world_simulation.py

  # ç‰¹å®šã®ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿å®Ÿè¡Œ
  python run_real_world_simulation.py --patterns daily weekly

  # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ã¿å®Ÿè¡Œ
  python run_real_world_simulation.py --edge-cases large_files many_files

  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªã®ã¿å®Ÿè¡Œ
  python run_real_world_simulation.py --scenarios new_user existing_user

  # è©³ç´°ãƒ­ã‚°å‡ºåŠ›
  python run_real_world_simulation.py --log-level DEBUG --log-file simulation.log
        """
    )

    # å®Ÿè¡Œå¯¾è±¡ã®é¸æŠ
    parser.add_argument(
        '--patterns',
        nargs='*',
        choices=['daily', 'weekly', 'monthly'],
        help='å®Ÿè¡Œã™ã‚‹ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæŒ‡å®šãªã—ã§å…¨å®Ÿè¡Œï¼‰'
    )

    parser.add_argument(
        '--edge-cases',
        nargs='*',
        choices=['large_files', 'many_files', 'special_chars'],
        help='å®Ÿè¡Œã™ã‚‹ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ï¼ˆæŒ‡å®šãªã—ã§å…¨å®Ÿè¡Œï¼‰'
    )

    parser.add_argument(
        '--scenarios',
        nargs='*',
        choices=['new_user', 'existing_user', 'bulk_processing'],
        help='å®Ÿè¡Œã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªï¼ˆæŒ‡å®šãªã—ã§å…¨å®Ÿè¡Œï¼‰'
    )

    # æ¤œè¨¼è¨­å®š
    parser.add_argument(
        '--enable-performance',
        action='store_true',
        default=True,
        help='ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚’æœ‰åŠ¹åŒ–'
    )

    parser.add_argument(
        '--enable-memory',
        action='store_true',
        default=True,
        help='ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’æœ‰åŠ¹åŒ–'
    )

    parser.add_argument(
        '--enable-error-injection',
        action='store_true',
        help='ã‚¨ãƒ©ãƒ¼æ³¨å…¥ã‚’æœ‰åŠ¹åŒ–'
    )

    parser.add_argument(
        '--max-execution-time',
        type=float,
        default=600.0,
        help='æœ€å¤§å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰'
    )

    parser.add_argument(
        '--max-memory-usage',
        type=float,
        default=3072.0,
        help='æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆMBï¼‰'
    )

    # ãƒ­ã‚°è¨­å®š
    parser.add_argument(
        '--log-level',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«'
    )

    parser.add_argument(
        '--log-file',
        help='ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )

    # å‡ºåŠ›è¨­å®š
    parser.add_argument(
        '--output-dir',
        default='validation_results/real_world_simulation',
        help='çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª'
    )

    parser.add_argument(
        '--output-file',
        help='çµæœå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰'
    )

    args = parser.parse_args()

    # ãƒ­ã‚°è¨­å®š
    setup_logging(args.log_level, args.log_file)

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ
    if not args.output_file:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.output_file = f"{args.output_dir}/real_world_simulation_results_{timestamp}.json"

    print("DocMindå®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™")
    print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.output_dir}")
    print(f"ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«: {args.log_level}")

    # æ¤œè¨¼è¨­å®šã®ä½œæˆ
    config = create_validation_config(args)

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–
    simulator = RealWorldSimulator(config)

    # çµæœæ ¼ç´ç”¨è¾æ›¸
    all_results = {
        'timestamp': datetime.now().isoformat(),
        'config': {
            'patterns': args.patterns,
            'edge_cases': args.edge_cases,
            'scenarios': args.scenarios,
            'max_execution_time': args.max_execution_time,
            'max_memory_usage': args.max_memory_usage
        },
        'usage_patterns': {},
        'edge_cases': {},
        'user_scenarios': {}
    }

    try:
        # ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        simulator.setup_test_environment()

        # ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        print("\n" + "="*60)
        print("ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        print("="*60)
        all_results['usage_patterns'] = run_usage_pattern_tests(simulator, args.patterns)

        # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        print("\n" + "="*60)
        print("ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        print("="*60)
        all_results['edge_cases'] = run_edge_case_tests(simulator, args.edge_cases)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        print("\n" + "="*60)
        print("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        print("="*60)
        all_results['user_scenarios'] = run_user_scenario_tests(simulator, args.scenarios)

        # çµ±è¨ˆæƒ…å ±ã®å–å¾—
        stats = simulator.get_statistics_summary()
        all_results['statistics'] = stats

        # çµæœã®ä¿å­˜
        save_results(all_results, args.output_file)

        # ã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
        print_summary(all_results)

    except KeyboardInterrupt:
        print("\næ¤œè¨¼ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 1

    except Exception as e:
        print(f"\næ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logging.exception("æ¤œè¨¼ã‚¨ãƒ©ãƒ¼")
        return 1

    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            simulator.teardown_test_environment()
            simulator.cleanup()
        except Exception as e:
            print(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    print("\nå®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸ")
    return 0


if __name__ == "__main__":
    sys.exit(main())
