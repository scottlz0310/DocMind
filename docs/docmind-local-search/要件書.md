# 要件書

## はじめに

DocMindは、ユーザーのローカルPCに保存された様々なドキュメント形式（PDF、Word、Excel、Markdown、テキストファイル）を包括的に検索できるローカルAI駆動デスクトップアプリケーションです。このアプリケーションは、従来のフルテキスト検索とローカルAIモデルを使用したセマンティック検索機能を組み合わせ、外部API依存関係なしで完全なオフライン機能を確保します。このPoCバージョンは、UIの美しさよりも検索精度とローカルパフォーマンスを優先し、APIベースAIサービスをサポートする将来の拡張性をサポートするアーキテクチャで設計されています。

## 要件

### 要件1: ローカルファイルインデックス作成と検索

**ユーザーストーリー:** ユーザーとして、フルテキスト検索を使用してローカルドキュメントをインデックス作成し検索したい。これにより、正確なキーワードマッチに基づいて関連ファイルを素早く見つけることができる。

#### 受入基準

1. ユーザーがフォルダパスを指定した場合、システムはサポートされているすべてのファイルタイプをクロールし、検索可能なインデックスを作成する
2. インデックス化されたフォルダ内でファイルが追加、変更、または削除された場合、システムはインデックス全体を再構築することなくインクリメンタルにインデックスを更新する
3. ユーザーがテキスト検索を実行した場合、システムは最大50,000ドキュメントで5秒以内に結果を返す
4. ファイルのインデックス作成時、システムはローカルストレージ用にWhooshまたはSQLiteベースのフルテキスト検索エンジンを使用する
5. アプリケーションが起動した場合、システムは再インデックス作成を要求することなく既存のインデックスを読み込む

### 要件2: セマンティック検索機能

**ユーザーストーリー:** ユーザーとして、自然言語クエリを使用してセマンティック検索を実行したい。これにより、正確なキーワードだけでなく、意味とコンテキストに基づいてドキュメントを見つけることができる。

#### 受入基準

1. ユーザーが自然言語クエリを入力した場合、システムはsentence-transformers all-MiniLM-L6-v2モデルを使用して埋め込みを生成する
2. ドキュメントを処理する場合、システムはすべてのインデックス化されたコンテンツ用にローカルで埋め込みを生成しキャッシュする
3. セマンティック検索を実行する場合、システムはクエリとドキュメント埋め込み間の類似性スコアを計算する
4. 埋め込みが生成された場合、システムは再利用のためにローカルキャッシュ（embeddings.pkl）に保存する
5. システムがオフラインの場合、セマンティック検索は外部API呼び出しなしで機能する

### 要件3: マルチフォーマットドキュメント処理

**ユーザーストーリー:** ユーザーとして、異なるドキュメント形式をシームレスに検索したい。これにより、情報が保存されているファイルタイプに関係なく情報を見つけることができる。

#### 受入基準

1. PDFファイルを処理する場合、システムはPyMuPDFを使用してテキストコンテンツを抽出する
2. Wordドキュメントを処理する場合、システムはpython-docxを使用してテキストコンテンツを抽出する
3. Excelファイルを処理する場合、システムはopenpyxlを使用してセルとシートからテキストを抽出する
4. Markdownファイルを処理する場合、システムは構造を保持しながらコンテンツを直接解析する
5. テキストファイルを処理する場合、システムは適切なエンコーディング検出でコンテンツを直接読み取る
6. ファイル抽出が失敗した場合、システムはエラーをログに記録し、他のファイルの処理を継続する

### 要件4: デスクトップユーザーインターフェース

**ユーザーストーリー:** ユーザーとして、シンプルな三パネルデスクトップインターフェースが欲しい。これにより、ドキュメントを効率的に閲覧、検索、プレビューできる。

#### 受入基準

1. アプリケーションが起動した場合、システムはPySide6を使用して三パネルレイアウトを表示する
2. 左パネルを表示する場合、システムはナビゲーション用のフォルダツリーを表示する
3. 中央パネルを表示する場合、システムはタイトル、スニペット、関連性スコアを含む検索結果を表示する
4. 右パネルを表示する場合、システムはドキュメントプレビューまたは要約を表示する
5. ユーザーが検索結果をクリックした場合、システムはプレビューパネルに完全なコンテンツを表示する
6. 検索結果が表示された場合、システムは明確なスコアリングでフルテキストとセマンティック検索結果の両方を表示する

### 要件5: オフライン操作とデータ管理

**ユーザーストーリー:** ユーザーとして、ローカルデータストレージでアプリケーションが完全にオフラインで動作することを望む。これにより、インターネット接続やプライバシーの懸念なしでドキュメントを検索できる。

#### 受入基準

1. アプリケーションが実行される場合、システムは外部API依存関係なしで動作する
2. メタデータを保存する場合、システムはドキュメントメタデータとインデックス管理用にdocuments.dbを使用する
3. 埋め込みを保存する場合、システムはドキュメントベクトルキャッシュ用にembeddings.pklを使用する
4. システムが起動した場合、システムはローカルストレージからすべての必要なモデルとデータを読み込む
5. ドキュメントを処理する場合、システムはsentence-transformersを使用してすべてのAIモデルがローカルで実行されることを確保する

### 要件6: パフォーマンスとスケーラビリティ

**ユーザーストーリー:** ユーザーとして、大規模なドキュメントコレクションでも高速な検索パフォーマンスを望む。これにより、広範囲なドキュメントライブラリで効率的に作業できる。

#### 受入基準

1. 最大50,000ドキュメントを検索する場合、システムは5秒以内に結果を返す
2. 新しいドキュメントをインデックス作成する場合、システムはUIをブロックすることなくインクリメンタルにファイルを処理する
3. アプリケーションを読み込む場合、システムはWindows 10/11で10秒以内に起動する
4. 並行操作を実行する場合、システムは適切なスレッド処理を通じて応答性のあるUIを維持する
5. メモリ使用量が合理的な制限を超えた場合、システムはパフォーマンスを最適化するためのキャッシュ戦略を実装する

### 要件7: システム互換性とアーキテクチャ

**ユーザーストーリー:** 開発者として、構造化された拡張可能なアーキテクチャを望む。これにより、システムは将来APIベースAIサービスで拡張できる。

#### 受入基準

1. アプリケーションを展開する場合、システムはWindows 10とWindows 11システムで実行される
2. アーキテクチャを設計する場合、システムはGUIフレームワークとしてPySide6を使用してPython 3.11-3.13を使用する
3. 検索機能を実装する場合、システムはローカルと将来のAPIベース検索機能を分離する
4. データを保存する場合、システムは将来の拡張に対応できるモジュラーデータアクセスパターンを使用する
5. システムが進化する場合、アーキテクチャはローカルとAPIベースAI処理の間の切り替えをサポートする
6. エラーを処理する場合、システムは包括的なログ記録とエラーハンドリングメカニズムを実装する

