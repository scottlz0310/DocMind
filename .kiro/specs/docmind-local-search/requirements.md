# 要件定義書

## はじめに

DocMindは、ユーザーのローカルPC上に保存された様々なドキュメント形式(PDF、Word、Excel、Markdown、テキストファイル)に対する包括的な検索を可能にするローカルAI搭載デスクトップアプリケーションです。このアプリケーションは、ローカルAIモデルを使用した従来の全文検索とセマンティック検索機能を組み合わせ、外部API依存なしに完全なオフライン機能を保証します。このPoC版は、UIの美観よりも検索精度とローカルパフォーマンスを優先し、将来のAPIベースAIサービスをサポートする拡張性を考慮したアーキテクチャで設計されています。

## 要件

### 要件1: ローカルファイルインデックスと検索

**ユーザーストーリー:** ユーザーとして、全文検索を使用してローカルドキュメントをインデックス化し検索したい。これにより、正確なキーワードマッチに基づいて関連ファイルを迅速に見つけることができる。

#### 受入基準

1. ユーザーがフォルダパスを指定した時、システムはサポートされているすべてのファイルタイプをクロールし、検索可能なインデックスを作成する
2. インデックス化されたフォルダでファイルが追加、変更、削除された時、システムは全体のインデックスを再構築することなく増分的にインデックスを更新する
3. ユーザーがテキスト検索を実行した時、システムは最大50,000ドキュメントに対して5秒以内に結果を返す
4. ファイルをインデックス化する時、システムはローカルストレージ用にWhooshまたはSQLiteベースの全文検索エンジンを使用する
5. アプリケーションが開始された時、システムは再インデックス化を必要とせずに既存のインデックスを読み込む

### 要件2: セマンティック検索機能

**ユーザーストーリー:** ユーザーとして、自然言語クエリを使用してセマンティック検索を実行したい。これにより、正確なキーワードだけでなく、意味と文脈に基づいてドキュメントを見つけることができる。

#### 受入基準

1. ユーザーが自然言語クエリを入力した時、システムは埋め込み生成にsentence-transformers all-MiniLM-L6-v2モデルを使用する
2. ドキュメントを処理する時、システムはインデックス化されたすべてのコンテンツに対して埋め込みをローカルで生成しキャッシュする
3. セマンティック検索を実行する時、システムはクエリとドキュメント埋め込み間の類似度スコアを計算する
4. 埋め込みが生成された時、システムは再利用のためにローカルキャッシュ(embeddings.pkl)に保存する
5. システムがオフラインの時、セマンティック検索は外部API呼び出しなしに機能する

### 要件3: マルチフォーマットドキュメント処理

**ユーザーストーリー:** ユーザーとして、異なるドキュメント形式をシームレスに検索したい。これにより、情報が保存されているファイルタイプに関係なく情報を見つけることができる。

#### 受入基準

1. PDFファイルを処理する時、システムはテキストコンテンツ抽出にPyMuPDFを使用する
2. Wordドキュメントを処理する時、システムはテキストコンテンツ抽出にpython-docxを使用する
3. Excelファイルを処理する時、システムはセルとシートからテキスト抽出にopenpyxlを使用する
4. Markdownファイルを処理する時、システムは構造を保持しながら直接コンテンツを解析する
5. テキストファイルを処理する時、システムは適切なエンコーディング検出で直接コンテンツを読み取る
6. ファイル抽出が失敗した時、システムはエラーをログに記録し他のファイルの処理を継続する

### 要件4: デスクトップユーザーインターフェース

**ユーザーストーリー:** ユーザーとして、シンプルな3ペインデスクトップインターフェースが欲しい。これにより、ドキュメントを効率的にブラウズ、検索、プレビューできる。

#### 受入基準

1. アプリケーションが起動した時、システムはPySide6を使用して3ペインレイアウトを表示する
2. 左ペインを表示する時、システムはナビゲーション用のフォルダツリーを表示する
3. 中央ペインを表示する時、システムはタイトル、スニペット、関連度スコア付きの検索結果を表示する
4. 右ペインを表示する時、システムはドキュメントプレビューまたは要約を表示する
5. ユーザーが検索結果をクリックした時、システムはプレビューペインに完全なコンテンツを表示する
6. 検索結果が表示された時、システムは明確なスコアリングで全文検索とセマンティック検索の両方の結果を表示する

### 要件5: オフライン動作とデータ管理

**ユーザーストーリー:** ユーザーとして、ローカルデータストレージで完全にオフラインで動作するアプリケーションが欲しい。これにより、インターネット接続やプライバシーの懸念なしにドキュメントを検索できる。

#### 受入基準

1. アプリケーションが実行された時、システムは外部API依存なしに動作する
2. メタデータを保存する時、システムはドキュメントメタデータとインデックス管理にdocuments.dbを使用する
3. 埋め込みを保存する時、システムはドキュメントベクターキャッシュにembeddings.pklを使用する
4. システムが開始された時、システムは必要なすべてのモデルとデータをローカルストレージから読み込む
5. ドキュメントを処理する時、システムはsentence-transformersを使用してすべてのAIモデルがローカルで実行されることを保証する

### 要件6: パフォーマンスとスケーラビリティ

**ユーザーストーリー:** ユーザーとして、大規模なドキュメントコレクションでも高速な検索パフォーマンスが欲しい。これにより、広範囲なドキュメントライブラリで効率的に作業できる。

#### 受入基準

1. 最大50,000ドキュメントを検索する時、システムは5秒以内に結果を返す
2. 新しいドキュメントをインデックス化する時、システムはUIをブロックすることなく増分的にファイルを処理する
3. アプリケーションを読み込む時、システムはWindows 10/11で10秒以内に起動する
4. 並行操作を実行する時、システムは適切なスレッド処理によりレスポンシブなUIを維持する
5. メモリ使用量が合理的な制限を超えた時、システムはパフォーマンス最適化のためのキャッシュ戦略を実装する

### 要件7: システム互換性とアーキテクチャ

**ユーザーストーリー:** 開発者として、よく構造化された拡張可能なアーキテクチャが欲しい。これにより、将来システムをAPIベースAIサービスで拡張できる。

#### 受入基準

1. アプリケーションをデプロイする時、システムはWindows 10およびWindows 11システムで動作する
2. アーキテクチャを設計する時、システムはGUIフレームワークにPySide6を使用したPython 3.11+を使用する
3. 検索機能を実装する時、システムはローカルと将来のAPIベース検索機能を分離する
4. データを保存する時、システムは将来の拡張に対応できるモジュラーデータアクセスパターンを使用する
5. システムが進化する時、アーキテクチャはローカルとAPIベースAI処理間の切り替えをサポートする
6. エラーを処理する時、システムは包括的なログ記録とエラーハンドリングメカニズムを実装する